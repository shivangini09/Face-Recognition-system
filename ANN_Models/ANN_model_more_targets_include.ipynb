{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13233, 3249)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# csvs/hog_95/extracted_features_hog_95.csv\n",
    "df1 = pd.read_csv('/home/swaksh/VSCode/prml_project/Face_Recognition/csvs/hog_95/extracted_features_hog_95.csv',header=None)\n",
    "df2 = pd.read_csv('/home/swaksh/VSCode/prml_project/Face_Recognition/csvs/hog_95/extracted_features_test_hog_95.csv',header=None)\n",
    "\n",
    "df = pd.concat([df1,df2])\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visuelise The occurence Of Each Name No. Of Times In the Dataset** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "George_W_Bush        530\n",
      "Colin_Powell         236\n",
      "Tony_Blair           144\n",
      "Donald_Rumsfeld      121\n",
      "Gerhard_Schroeder    109\n",
      "                    ... \n",
      "Brian_De_Palma         1\n",
      "David_Rivkin_Jr        1\n",
      "Koichiro_Matsuura      1\n",
      "Olivera_Labus          1\n",
      "Jalen_Rose             1\n",
      "Name: count, Length: 5749, dtype: int64\n",
      "530\n",
      "236\n",
      "144\n",
      "121\n",
      "109\n",
      "77\n",
      "71\n",
      "60\n",
      "55\n",
      "53\n",
      "52\n",
      "52\n",
      "49\n",
      "48\n",
      "44\n",
      "42\n",
      "42\n",
      "41\n",
      "41\n",
      "39\n",
      "39\n",
      "37\n",
      "36\n",
      "35\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "32\n",
      "32\n",
      "31\n",
      "31\n",
      "30\n",
      "30\n",
      "29\n",
      "29\n",
      "28\n",
      "28\n",
      "27\n",
      "26\n",
      "26\n",
      "25\n",
      "24\n",
      "24\n",
      "24\n",
      "23\n",
      "23\n",
      "23\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "16\n",
      "16\n",
      "16\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "name_counts = df.iloc[:,0].value_counts()\n",
    "\n",
    "print(name_counts)\n",
    "\n",
    "for value in df.iloc[:,0].value_counts():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing What Will Be The Size OF The Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4324\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for value in name_counts:\n",
    "    if(value >=10): count+= value\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering The Dataset With Names That Occurs More than 10 Times** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4324, 3249)\n"
     ]
    }
   ],
   "source": [
    "filtered_names_indices = name_counts[name_counts >= 10].index.to_list()\n",
    "\n",
    "new_df_gte_10 = df[df.iloc[:,0].isin(filtered_names_indices)]\n",
    "\n",
    "print(new_df_gte_10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Filtered Dataset Into Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4324, 3248)   (4324,)\n"
     ]
    }
   ],
   "source": [
    "y = new_df_gte_10.iloc[:,0]\n",
    "X = new_df_gte_10.drop(columns=[new_df_gte_10.columns[0]])\n",
    "print(X.shape,\" \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization Of The Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3459, 3248) \n",
      " (865, 3248) \n",
      " (3459,) \n",
      " (865,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=42)\n",
    "print(X_train.shape,\"\\n\",X_test.shape,\"\\n\",y_train.shape,\"\\n\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train >= 45: (1092, 3248)\n",
      "y_train >= 45: (1092,)\n",
      "X_train < 45: (2367, 3248)\n",
      "y_train < 45: (2367,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "labels, counts = unique_counts\n",
    "\n",
    "indices_greater_than_45 = np.where(counts >= 45)[0]\n",
    "indices_less_than_45 = np.where(counts < 45)[0]\n",
    "\n",
    "X_train_greater_than_45 = X_train[np.isin(y_train, labels[indices_greater_than_45])]\n",
    "X_train_less_than_45 = X_train[np.isin(y_train, labels[indices_less_than_45])]\n",
    "\n",
    "y_train_greater_than_45 = y_train[np.isin(y_train, labels[indices_greater_than_45])]\n",
    "y_train_less_than_45 = y_train[np.isin(y_train, labels[indices_less_than_45])]\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"X_train >= 45:\", X_train_greater_than_45.shape)\n",
    "print(\"y_train >= 45:\", y_train_greater_than_45.shape)\n",
    "print(\"X_train < 45:\", X_train_less_than_45.shape)\n",
    "print(\"y_train < 45:\", y_train_less_than_45.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert y_train and y_test into Numeric Values As ANN Trains On Numerical Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 5 0] \n",
      " 8\n"
     ]
    }
   ],
   "source": [
    "y_train_greater_than_45 = y_train_greater_than_45.values.flatten()\n",
    "labels_train_gt45 ,unique_train_gt45 = pd.factorize(y_train_greater_than_45)\n",
    "\n",
    "print(labels_train_gt45,\"\\n\",len(unique_train_gt45))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtered Data Labels Calculate Value Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    426\n",
      "2    188\n",
      "1    120\n",
      "6     97\n",
      "5     88\n",
      "7     64\n",
      "4     58\n",
      "3     51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels_count_train = pd.Series(labels_train_gt45).value_counts()\n",
    "print(labels_count_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapping The Names With The Numeric Value(Labels) Passed As The y_train To The Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1092,)\n"
     ]
    }
   ],
   "source": [
    "y_train_greater_than_45 = np.array(labels_train_gt45)\n",
    "print(y_train_greater_than_45.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,) (8,)\n"
     ]
    }
   ],
   "source": [
    "labels_unique_gt45 = np.unique(labels_train_gt45)\n",
    "print(labels_unique_gt45.shape, unique_train_gt45.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'George_W_Bush', 1: 'Tony_Blair', 2: 'Colin_Powell', 3: 'Junichiro_Koizumi', 4: 'Hugo_Chavez', 5: 'Gerhard_Schroeder', 6: 'Donald_Rumsfeld', 7: 'Ariel_Sharon'}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "y_train_labels_to_names_gt45 = {}\n",
    "for i in range(len(labels_unique_gt45)):\n",
    "    y_train_labels_to_names_gt45[labels_unique_gt45[i]] = unique_train_gt45[i]\n",
    "    \n",
    "print(y_train_labels_to_names_gt45)\n",
    "print(len(y_train_labels_to_names_gt45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarly For The Labels Count LessThan45**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2 ... 125  18 114] \n",
      " 150\n",
      "19     42\n",
      "18     42\n",
      "81     41\n",
      "48     41\n",
      "82     40\n",
      "       ..\n",
      "138     7\n",
      "76      7\n",
      "126     7\n",
      "95      6\n",
      "141     6\n",
      "Name: count, Length: 150, dtype: int64\n",
      "(2367,)\n",
      "(150,) (150,)\n",
      "{0: 'Tom_Hanks', 1: 'Silvio_Berlusconi', 2: 'Tom_Daschle', 3: 'John_Snow', 4: 'Renee_Zellweger', 5: 'John_Paul_II', 6: 'Hu_Jintao', 7: 'David_Beckham', 8: 'Jose_Maria_Aznar', 9: 'Hamid_Karzai', 10: 'Bill_Gates', 11: 'John_Bolton', 12: 'Atal_Bihari_Vajpayee', 13: 'Paul_Bremer', 14: 'Jennifer_Capriati', 15: 'Mahmoud_Abbas', 16: 'Igor_Ivanov', 17: 'Juan_Carlos_Ferrero', 18: 'Serena_Williams', 19: 'Jean_Chretien', 20: 'Dick_Cheney', 21: 'Norah_Jones', 22: 'Michael_Bloomberg', 23: 'Arnold_Schwarzenegger', 24: 'Lleyton_Hewitt', 25: 'Megawati_Sukarnoputri', 26: 'Alejandro_Toledo', 27: 'Julie_Gerberding', 28: 'Queen_Elizabeth_II', 29: 'Roh_Moo-hyun', 30: 'Naomi_Watts', 31: 'Charles_Moose', 32: 'Kim_Clijsters', 33: 'Alvaro_Uribe', 34: 'Rubens_Barrichello', 35: 'Lance_Armstrong', 36: 'Andre_Agassi', 37: 'Jennifer_Lopez', 38: 'Nicole_Kidman', 39: 'Pete_Sampras', 40: 'Gloria_Macapagal_Arroyo', 41: 'Jacques_Rogge', 42: 'Hans_Blix', 43: 'Roger_Federer', 44: 'Vicente_Fox', 45: 'Tang_Jiaxuan', 46: 'Howard_Dean', 47: 'Eduardo_Duhalde', 48: 'Jacques_Chirac', 49: 'Ann_Veneman', 50: 'Richard_Gephardt', 51: 'Venus_Williams', 52: 'John_Howard', 53: 'Joe_Lieberman', 54: 'James_Blake', 55: 'Winona_Ryder', 56: 'Jeremy_Greenstock', 57: 'Jack_Straw', 58: 'John_Kerry', 59: 'Fidel_Castro', 60: 'Harrison_Ford', 61: 'Saddam_Hussein', 62: 'Tim_Henman', 63: 'Jiri_Novak', 64: 'Tom_Ridge', 65: 'Salma_Hayek', 66: 'Wen_Jiabao', 67: 'Lindsay_Davenport', 68: 'Muhammad_Ali', 69: 'Kofi_Annan', 70: 'Jean_Charest', 71: 'Abdullah_Gul', 72: 'Gray_Davis', 73: 'Mark_Philippoussis', 74: 'Carlos_Menem', 75: 'John_Negroponte', 76: 'Javier_Solana', 77: 'Bill_Simon', 78: 'Spencer_Abraham', 79: 'Tommy_Franks', 80: 'Sergey_Lavrov', 81: 'Vladimir_Putin', 82: 'Luiz_Inacio_Lula_da_Silva', 83: 'Kim_Ryong-sung', 84: 'Jason_Kidd', 85: 'Amelie_Mauresmo', 86: 'Rudolph_Giuliani', 87: 'Catherine_Zeta-Jones', 88: 'Paul_Burrell', 89: 'Jiang_Zemin', 90: 'John_Ashcroft', 91: 'Michael_Jackson', 92: 'Richard_Myers', 93: 'Trent_Lott', 94: 'David_Nalbandian', 95: 'Jean-David_Levitte', 96: 'Tiger_Woods', 97: 'Anna_Kournikova', 98: 'Nestor_Kirchner', 99: 'Nicanor_Duarte_Frutos', 100: 'Joschka_Fischer', 101: 'Bill_Clinton', 102: 'Angelina_Jolie', 103: 'Adrien_Brody', 104: 'Julianne_Moore', 105: 'Paradorn_Srichaphan', 106: 'George_Robertson', 107: 'Mohammad_Khatami', 108: 'Mohammed_Al-Douri', 109: 'Laura_Bush', 110: 'Condoleezza_Rice', 111: 'Recep_Tayyip_Erdogan', 112: 'Carlos_Moya', 113: 'Guillermo_Coria', 114: 'Mahathir_Mohamad', 115: 'Yoriko_Kawaguchi', 116: 'Ari_Fleischer', 117: 'Lucio_Gutierrez', 118: 'Paul_Wolfowitz', 119: 'Meryl_Streep', 120: 'Jennifer_Aniston', 121: 'Edmund_Stoiber', 122: 'Gonzalo_Sanchez_de_Lozada', 123: 'Jackie_Chan', 124: 'Dominique_de_Villepin', 125: 'Andy_Roddick', 126: 'Bill_McBride', 127: 'Mike_Weir', 128: 'Keanu_Reeves', 129: 'Taha_Yassin_Ramadan', 130: 'George_HW_Bush', 131: 'Pervez_Musharraf', 132: 'Britney_Spears', 133: 'Gordon_Brown', 134: 'Jeb_Bush', 135: 'Ricardo_Lagos', 136: 'Tom_Cruise', 137: 'Pierce_Brosnan', 138: 'Tommy_Thompson', 139: 'Sergio_Vieira_De_Mello', 140: 'Walter_Mondale', 141: 'Jennifer_Garner', 142: 'Nancy_Pelosi', 143: 'Halle_Berry', 144: 'James_Kelly', 145: 'Richard_Gere', 146: 'Hillary_Clinton', 147: 'John_Allen_Muhammad', 148: 'Ian_Thorpe', 149: 'Michael_Schumacher'}\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "y_train_less_than_45 = y_train_less_than_45.values.flatten()\n",
    "labels_train_lt45 ,unique_train_lt45 = pd.factorize(y_train_less_than_45)\n",
    "\n",
    "print(labels_train_lt45,\"\\n\",len(unique_train_lt45))\n",
    "\n",
    "labels_count_train = pd.Series(labels_train_lt45).value_counts()\n",
    "print(labels_count_train)\n",
    "\n",
    "y_train_less_than_45 = np.array(labels_train_lt45)\n",
    "print(y_train_less_than_45.shape)\n",
    "\n",
    "labels_unique_lt45 = np.unique(labels_train_lt45)\n",
    "print(labels_unique_lt45.shape, unique_train_lt45.shape)\n",
    "\n",
    "y_train_labels_to_names_lt45 = {}\n",
    "for i in range(len(labels_unique_lt45)):\n",
    "    y_train_labels_to_names_lt45[labels_unique_lt45[i]] = unique_train_lt45[i]\n",
    "    \n",
    "print(y_train_labels_to_names_lt45)\n",
    "print(len(y_train_labels_to_names_lt45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train The Data On ANN Model And Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swaksh/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.0350 - loss: 4.9606\n",
      "Epoch 2/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.3604 - loss: 2.8227\n",
      "Epoch 3/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9094 - loss: 0.4377\n",
      "Epoch 4/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9862 - loss: 0.0797\n",
      "Epoch 5/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9815 - loss: 0.1108\n",
      "Epoch 6/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9889 - loss: 0.0480\n",
      "Epoch 7/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9977 - loss: 0.0158\n",
      "Epoch 8/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9986 - loss: 0.0097\n",
      "Epoch 9/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 10/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.3945e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.5364e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.0684e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.7290e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.5090e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.3271e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.2135e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.0319e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 9.3645e-05\n",
      "Epoch 19/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 8.2809e-05\n",
      "Epoch 20/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.7957e-05\n",
      "Epoch 21/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.0299e-05\n",
      "Epoch 22/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 6.4713e-05\n",
      "Epoch 23/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.9414e-05\n",
      "Epoch 24/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 5.6441e-05\n",
      "Epoch 25/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 5.0066e-05\n",
      "Epoch 26/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.8584e-05\n",
      "Epoch 27/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.5639e-05\n",
      "Epoch 28/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.2021e-05\n",
      "Epoch 29/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.0511e-05\n",
      "Epoch 30/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.7103e-05\n",
      "Epoch 31/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.6624e-05\n",
      "Epoch 32/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.4926e-05\n",
      "Epoch 33/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.2404e-05\n",
      "Epoch 34/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.0496e-05\n",
      "Epoch 35/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.7462e-05\n",
      "Epoch 36/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.8580e-05\n",
      "Epoch 37/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.7005e-05\n",
      "Epoch 38/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.4964e-05\n",
      "Epoch 39/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.5409e-05\n",
      "Epoch 40/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.3428e-05\n",
      "Epoch 41/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.2648e-05\n",
      "Epoch 42/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.1306e-05\n",
      "Epoch 43/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.9857e-05\n",
      "Epoch 44/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.8440e-05\n",
      "Epoch 45/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.8549e-05\n",
      "Epoch 46/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.7785e-05\n",
      "Epoch 47/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.6551e-05\n",
      "Epoch 48/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.6920e-05\n",
      "Epoch 49/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.5265e-05\n",
      "Epoch 50/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.5239e-05\n",
      "Epoch 51/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.4431e-05\n",
      "Epoch 52/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.4179e-05\n",
      "Epoch 53/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.3825e-05\n",
      "Epoch 54/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3196e-05\n",
      "Epoch 55/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2573e-05\n",
      "Epoch 56/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.2108e-05\n",
      "Epoch 57/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1888e-05\n",
      "Epoch 58/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1307e-05\n",
      "Epoch 59/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.1129e-05\n",
      "Epoch 60/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.0635e-05\n",
      "Epoch 61/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0330e-05\n",
      "Epoch 62/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0238e-05\n",
      "Epoch 63/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.6367e-06\n",
      "Epoch 64/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.2377e-06\n",
      "Epoch 65/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 9.1324e-06\n",
      "Epoch 66/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.5679e-06\n",
      "Epoch 67/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.7785e-06\n",
      "Epoch 68/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.6774e-06\n",
      "Epoch 69/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.9442e-06\n",
      "Epoch 70/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 7.7733e-06\n",
      "Epoch 71/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 7.5047e-06\n",
      "Epoch 72/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.3774e-06\n",
      "Epoch 73/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.2004e-06\n",
      "Epoch 74/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.8124e-06\n",
      "Epoch 75/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 6.7352e-06\n",
      "Epoch 76/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 6.4857e-06\n",
      "Epoch 77/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.4164e-06\n",
      "Epoch 78/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.8009e-06\n",
      "Epoch 79/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 5.9713e-06\n",
      "Epoch 80/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.9686e-06\n",
      "Epoch 81/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.9117e-06\n",
      "Epoch 82/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.7109e-06\n",
      "Epoch 83/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.3817e-06\n",
      "Epoch 84/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 5.0846e-06\n",
      "Epoch 85/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.9616e-06\n",
      "Epoch 86/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.0709e-06\n",
      "Epoch 87/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.9600e-06\n",
      "Epoch 88/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.8625e-06\n",
      "Epoch 89/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.6379e-06\n",
      "Epoch 90/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.4818e-06\n",
      "Epoch 91/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.3903e-06\n",
      "Epoch 92/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.1746e-06\n",
      "Epoch 93/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.0131e-06\n",
      "Epoch 94/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.9087e-06\n",
      "Epoch 95/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.8375e-06\n",
      "Epoch 96/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.7555e-06\n",
      "Epoch 97/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 3.6839e-06\n",
      "Epoch 98/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.7710e-06\n",
      "Epoch 99/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.5442e-06\n",
      "Epoch 100/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.5645e-06\n",
      "Epoch 101/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.3533e-06\n",
      "Epoch 102/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.3021e-06\n",
      "Epoch 103/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.2178e-06\n",
      "Epoch 104/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.2003e-06\n",
      "Epoch 105/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 3.0304e-06\n",
      "Epoch 106/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.0000e-06\n",
      "Epoch 107/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.0012e-06\n",
      "Epoch 108/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.8574e-06\n",
      "Epoch 109/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.8932e-06\n",
      "Epoch 110/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.7874e-06\n",
      "Epoch 111/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.6138e-06\n",
      "Epoch 112/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.5467e-06\n",
      "Epoch 113/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.5259e-06\n",
      "Epoch 114/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.4394e-06\n",
      "Epoch 115/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.3833e-06\n",
      "Epoch 116/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.3371e-06\n",
      "Epoch 117/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.3387e-06\n",
      "Epoch 118/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.2703e-06\n",
      "Epoch 119/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.2019e-06\n",
      "Epoch 120/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.1244e-06\n",
      "Epoch 121/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.0849e-06\n",
      "Epoch 122/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.1068e-06\n",
      "Epoch 123/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.9426e-06\n",
      "Epoch 124/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.9426e-06\n",
      "Epoch 125/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.9864e-06\n",
      "Epoch 126/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.8831e-06\n",
      "Epoch 127/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.8492e-06\n",
      "Epoch 128/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.7308e-06\n",
      "Epoch 129/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.7860e-06\n",
      "Epoch 130/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.7444e-06\n",
      "Epoch 131/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.6806e-06\n",
      "Epoch 132/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.6218e-06\n",
      "Epoch 133/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.6153e-06\n",
      "Epoch 134/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.5525e-06\n",
      "Epoch 135/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.5585e-06\n",
      "Epoch 136/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5002e-06\n",
      "Epoch 137/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4325e-06\n",
      "Epoch 138/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.4686e-06\n",
      "Epoch 139/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.4227e-06\n",
      "Epoch 140/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.3462e-06\n",
      "Epoch 141/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.3660e-06\n",
      "Epoch 142/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.2761e-06\n",
      "Epoch 143/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2872e-06\n",
      "Epoch 144/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.2365e-06\n",
      "Epoch 145/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.2462e-06\n",
      "Epoch 146/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1670e-06\n",
      "Epoch 147/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.2324e-06\n",
      "Epoch 148/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2008e-06\n",
      "Epoch 149/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.1659e-06\n",
      "Epoch 150/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.1253e-06\n",
      "Epoch 151/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.0619e-06\n",
      "Epoch 152/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.0969e-06\n",
      "Epoch 153/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.0465e-06\n",
      "Epoch 154/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.0236e-06\n",
      "Epoch 155/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 9.9660e-07\n",
      "Epoch 156/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.7287e-07\n",
      "Epoch 157/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.9473e-07\n",
      "Epoch 158/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 9.4400e-07\n",
      "Epoch 159/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.2114e-07\n",
      "Epoch 160/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.3770e-07\n",
      "Epoch 161/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.9098e-07\n",
      "Epoch 162/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.8914e-07\n",
      "Epoch 163/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.6388e-07\n",
      "Epoch 164/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.2388e-07\n",
      "Epoch 165/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.9082e-07\n",
      "Epoch 166/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.1479e-07\n",
      "Epoch 167/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.9287e-07\n",
      "Epoch 168/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.6590e-07\n",
      "Epoch 169/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.5546e-07\n",
      "Epoch 170/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.3056e-07\n",
      "Epoch 171/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.2272e-07\n",
      "Epoch 172/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.9922e-07\n",
      "Epoch 173/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.9889e-07\n",
      "Epoch 174/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 6.4297e-07\n",
      "Epoch 175/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 6.7091e-07\n",
      "Epoch 176/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 6.3465e-07\n",
      "Epoch 177/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.7260e-07\n",
      "Epoch 178/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.3903e-07\n",
      "Epoch 179/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.0666e-07\n",
      "Epoch 180/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.8730e-07\n",
      "Epoch 181/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 6.0998e-07\n",
      "Epoch 182/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.9103e-07\n",
      "Epoch 183/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.6520e-07\n",
      "Epoch 184/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.6766e-07\n",
      "Epoch 185/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.4451e-07\n",
      "Epoch 186/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.3717e-07\n",
      "Epoch 187/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.3812e-07\n",
      "Epoch 188/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 5.0908e-07\n",
      "Epoch 189/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.7760e-07\n",
      "Epoch 190/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.9867e-07\n",
      "Epoch 191/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 4.9481e-07\n",
      "Epoch 192/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.8322e-07\n",
      "Epoch 193/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.7167e-07\n",
      "Epoch 194/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.7441e-07\n",
      "Epoch 195/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.4120e-07\n",
      "Epoch 196/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.4237e-07\n",
      "Epoch 197/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.1705e-07\n",
      "Epoch 198/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.2221e-07\n",
      "Epoch 199/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.1047e-07\n",
      "Epoch 200/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.0141e-07\n",
      "Epoch 201/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.0452e-07\n",
      "Epoch 202/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.8414e-07\n",
      "Epoch 203/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.7514e-07\n",
      "Epoch 204/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.7653e-07\n",
      "Epoch 205/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.4396e-07\n",
      "Epoch 206/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 3.6262e-07\n",
      "Epoch 207/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.5170e-07\n",
      "Epoch 208/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.3723e-07\n",
      "Epoch 209/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.3726e-07\n",
      "Epoch 210/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.2122e-07\n",
      "Epoch 211/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.1676e-07\n",
      "Epoch 212/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.1424e-07\n",
      "Epoch 213/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.0749e-07\n",
      "Epoch 214/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.1263e-07\n",
      "Epoch 215/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.9341e-07\n",
      "Epoch 216/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.8416e-07\n",
      "Epoch 217/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.8426e-07\n",
      "Epoch 218/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 2.6477e-07\n",
      "Epoch 219/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.7363e-07\n",
      "Epoch 220/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.5836e-07\n",
      "Epoch 221/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.7533e-07\n",
      "Epoch 222/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.4978e-07\n",
      "Epoch 223/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.4838e-07\n",
      "Epoch 224/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.6055e-07\n",
      "Epoch 225/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.3863e-07\n",
      "Epoch 226/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.2962e-07\n",
      "Epoch 227/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.3371e-07\n",
      "Epoch 228/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.2555e-07\n",
      "Epoch 229/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.2120e-07\n",
      "Epoch 230/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.2077e-07\n",
      "Epoch 231/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.0689e-07\n",
      "Epoch 232/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.0685e-07\n",
      "Epoch 233/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.0223e-07\n",
      "Epoch 234/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.9708e-07\n",
      "Epoch 235/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.0082e-07\n",
      "Epoch 236/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.9114e-07\n",
      "Epoch 237/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.8658e-07\n",
      "Epoch 238/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.8448e-07\n",
      "Epoch 239/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.7832e-07\n",
      "Epoch 240/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.7805e-07\n",
      "Epoch 241/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.7505e-07\n",
      "Epoch 242/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.7329e-07\n",
      "Epoch 243/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.6493e-07\n",
      "Epoch 244/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.7366e-07\n",
      "Epoch 245/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5673e-07\n",
      "Epoch 246/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5761e-07\n",
      "Epoch 247/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.4965e-07\n",
      "Epoch 248/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5375e-07\n",
      "Epoch 249/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5286e-07\n",
      "Epoch 250/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.4543e-07\n",
      "Epoch 251/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4232e-07\n",
      "Epoch 252/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3863e-07\n",
      "Epoch 253/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.4343e-07\n",
      "Epoch 254/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.3543e-07\n",
      "Epoch 255/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.2738e-07\n",
      "Epoch 256/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.2780e-07\n",
      "Epoch 257/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1975e-07\n",
      "Epoch 258/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1434e-07\n",
      "Epoch 259/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.2032e-07\n",
      "Epoch 260/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.1960e-07\n",
      "Epoch 261/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1265e-07\n",
      "Epoch 262/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.1187e-07\n",
      "Epoch 263/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.0952e-07\n",
      "Epoch 264/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.0490e-07\n",
      "Epoch 265/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.1140e-07\n",
      "Epoch 266/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.0621e-07\n",
      "Epoch 267/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0048e-07\n",
      "Epoch 268/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.0030e-07\n",
      "Epoch 269/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.8612e-08\n",
      "Epoch 270/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.9129e-08\n",
      "Epoch 271/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 9.5837e-08\n",
      "Epoch 272/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 8.9168e-08\n",
      "Epoch 273/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 8.8888e-08\n",
      "Epoch 274/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.9452e-08\n",
      "Epoch 275/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.4057e-08\n",
      "Epoch 276/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.7379e-08\n",
      "Epoch 277/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.6090e-08\n",
      "Epoch 278/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.5864e-08\n",
      "Epoch 279/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.9733e-08\n",
      "Epoch 280/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.1580e-08\n",
      "Epoch 281/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 7.9109e-08\n",
      "Epoch 282/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.3392e-08\n",
      "Epoch 283/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.1166e-08\n",
      "Epoch 284/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.7929e-08\n",
      "Epoch 285/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.5703e-08\n",
      "Epoch 286/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.2470e-08\n",
      "Epoch 287/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.0011e-08\n",
      "Epoch 288/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.2090e-08\n",
      "Epoch 289/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.9587e-08\n",
      "Epoch 290/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.8977e-08\n",
      "Epoch 291/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.3319e-08\n",
      "Epoch 292/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.7167e-08\n",
      "Epoch 293/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 6.3668e-08\n",
      "Epoch 294/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 6.5467e-08\n",
      "Epoch 295/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.0927e-08\n",
      "Epoch 296/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.0173e-08\n",
      "Epoch 297/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.0731e-08\n",
      "Epoch 298/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.8391e-08\n",
      "Epoch 299/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.9706e-08\n",
      "Epoch 300/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.7257e-08\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(2048,activation='relu',input_shape=(3248,)),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dense(512,activation='relu'),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    keras.layers.Dense(150,activation='softmax'),  # Here 4883 are my unique labels\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# X_train_less_than_45 = X_train_less_than_45.astype('float32')  # Convert to float if not already\n",
    "# y_train_less_than_45 = y_train_less_than_45.astype('int32')  # Convert to int if not already\n",
    "\n",
    "X_train_less_than_45 = np.array(X_train_less_than_45)\n",
    "y_train_less_than_45 = np.array(y_train_less_than_45)\n",
    "\n",
    "model.fit(X_train_less_than_45,y_train_less_than_45,epochs=300,batch_size=64)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "predictions_lt45 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swaksh/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3459,)\n",
      "Epoch 1/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.3725 - loss: 2.2224\n",
      "Epoch 2/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8607 - loss: 0.4543\n",
      "Epoch 3/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9855 - loss: 0.0406\n",
      "Epoch 4/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9962 - loss: 0.0157\n",
      "Epoch 5/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9976 - loss: 0.0075\n",
      "Epoch 6/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9995 - loss: 0.0074\n",
      "Epoch 7/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9960 - loss: 0.0059\n",
      "Epoch 8/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.2471e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.4755e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.3729e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.0959e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.9816e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.5977e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.9240e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.4786e-05\n",
      "Epoch 16/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.8742e-05\n",
      "Epoch 17/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7611e-05\n",
      "Epoch 18/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.4620e-05\n",
      "Epoch 19/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.3428e-05\n",
      "Epoch 20/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.9707e-05\n",
      "Epoch 21/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.0417e-05\n",
      "Epoch 22/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.7667e-05\n",
      "Epoch 23/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.7189e-05\n",
      "Epoch 24/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.6870e-05\n",
      "Epoch 25/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.7320e-05\n",
      "Epoch 26/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.6890e-05\n",
      "Epoch 27/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.3208e-05\n",
      "Epoch 28/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.4647e-05\n",
      "Epoch 29/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.3790e-05\n",
      "Epoch 30/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.3293e-05\n",
      "Epoch 31/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.4055e-05\n",
      "Epoch 32/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1874e-05\n",
      "Epoch 33/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1512e-05\n",
      "Epoch 34/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0583e-05\n",
      "Epoch 35/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.1006e-05\n",
      "Epoch 36/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.0287e-05\n",
      "Epoch 37/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0126e-05\n",
      "Epoch 38/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.1784e-06\n",
      "Epoch 39/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.8963e-06\n",
      "Epoch 40/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.2768e-06\n",
      "Epoch 41/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.0187e-06\n",
      "Epoch 42/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.9638e-06\n",
      "Epoch 43/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.2219e-06\n",
      "Epoch 44/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.4812e-06\n",
      "Epoch 45/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.8491e-06\n",
      "Epoch 46/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.5027e-06\n",
      "Epoch 47/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.7919e-06\n",
      "Epoch 48/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.2464e-06\n",
      "Epoch 49/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.5173e-06\n",
      "Epoch 50/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.9322e-06\n",
      "Epoch 51/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.9750e-06\n",
      "Epoch 52/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.3761e-06\n",
      "Epoch 53/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.6199e-06\n",
      "Epoch 54/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 5.3533e-06\n",
      "Epoch 55/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 4.9374e-06\n",
      "Epoch 56/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.8415e-06\n",
      "Epoch 57/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.8775e-06\n",
      "Epoch 58/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.7112e-06\n",
      "Epoch 59/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.2397e-06\n",
      "Epoch 60/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.5373e-06\n",
      "Epoch 61/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.5589e-06\n",
      "Epoch 62/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.0954e-06\n",
      "Epoch 63/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.9569e-06\n",
      "Epoch 64/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.5927e-06\n",
      "Epoch 65/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.1184e-06\n",
      "Epoch 66/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.8374e-06\n",
      "Epoch 67/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.4307e-06\n",
      "Epoch 68/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.5164e-06\n",
      "Epoch 69/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.5032e-06\n",
      "Epoch 70/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.3439e-06\n",
      "Epoch 71/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.5282e-06\n",
      "Epoch 72/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.0412e-06\n",
      "Epoch 73/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.2765e-06\n",
      "Epoch 74/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.1170e-06\n",
      "Epoch 75/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.9869e-06\n",
      "Epoch 76/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.9529e-06\n",
      "Epoch 77/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.6399e-06\n",
      "Epoch 78/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.6371e-06\n",
      "Epoch 79/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.4366e-06\n",
      "Epoch 80/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.8839e-06\n",
      "Epoch 81/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.5279e-06\n",
      "Epoch 82/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.4783e-06\n",
      "Epoch 83/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.2850e-06\n",
      "Epoch 84/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.5093e-06\n",
      "Epoch 85/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.3931e-06\n",
      "Epoch 86/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.3163e-06\n",
      "Epoch 87/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.1395e-06\n",
      "Epoch 88/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.1843e-06\n",
      "Epoch 89/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.2808e-06\n",
      "Epoch 90/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.0802e-06\n",
      "Epoch 91/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.9799e-06\n",
      "Epoch 92/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.1454e-06\n",
      "Epoch 93/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.9654e-06\n",
      "Epoch 94/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.9688e-06\n",
      "Epoch 95/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.9534e-06\n",
      "Epoch 96/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.8575e-06\n",
      "Epoch 97/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.8797e-06\n",
      "Epoch 98/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.8097e-06\n",
      "Epoch 99/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.7830e-06\n",
      "Epoch 100/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.8444e-06\n",
      "Epoch 101/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.6797e-06\n",
      "Epoch 102/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5609e-06\n",
      "Epoch 103/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.6586e-06\n",
      "Epoch 104/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.4274e-06\n",
      "Epoch 105/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.6495e-06\n",
      "Epoch 106/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.6083e-06\n",
      "Epoch 107/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5097e-06\n",
      "Epoch 108/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.3993e-06\n",
      "Epoch 109/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.2748e-06\n",
      "Epoch 110/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.5679e-06\n",
      "Epoch 111/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.4065e-06\n",
      "Epoch 112/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.3167e-06\n",
      "Epoch 113/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.1914e-06\n",
      "Epoch 114/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.3078e-06\n",
      "Epoch 115/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.2727e-06\n",
      "Epoch 116/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.2850e-06\n",
      "Epoch 117/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.2621e-06\n",
      "Epoch 118/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1021e-06\n",
      "Epoch 119/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.2251e-06\n",
      "Epoch 120/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2523e-06\n",
      "Epoch 121/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1873e-06\n",
      "Epoch 122/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.2451e-06\n",
      "Epoch 123/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1845e-06\n",
      "Epoch 124/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.0989e-06\n",
      "Epoch 125/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1226e-06\n",
      "Epoch 126/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.2244e-06\n",
      "Epoch 127/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2127e-06\n",
      "Epoch 128/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.1106e-06\n",
      "Epoch 129/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0967e-06\n",
      "Epoch 130/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.3016e-07\n",
      "Epoch 131/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.9768e-07\n",
      "Epoch 132/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0071e-06\n",
      "Epoch 133/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0879e-06\n",
      "Epoch 134/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.4276e-07\n",
      "Epoch 135/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.0010e-06\n",
      "Epoch 136/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.2103e-07\n",
      "Epoch 137/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 8.1540e-07\n",
      "Epoch 138/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 7.8837e-07\n",
      "Epoch 139/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 8.3835e-07\n",
      "Epoch 140/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.2972e-07\n",
      "Epoch 141/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.0146e-06\n",
      "Epoch 142/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.7448e-07\n",
      "Epoch 143/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 8.8568e-07\n",
      "Epoch 144/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.7213e-07\n",
      "Epoch 145/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.8358e-07\n",
      "Epoch 146/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.3313e-07\n",
      "Epoch 147/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.8298e-07\n",
      "Epoch 148/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.9588e-07\n",
      "Epoch 149/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.0186e-07\n",
      "Epoch 150/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.3987e-07\n",
      "Epoch 151/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.9085e-07\n",
      "Epoch 152/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.0037e-07\n",
      "Epoch 153/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 6.7460e-07\n",
      "Epoch 154/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 6.5764e-07\n",
      "Epoch 155/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.1261e-07\n",
      "Epoch 156/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.9440e-07\n",
      "Epoch 157/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.2944e-07\n",
      "Epoch 158/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.7861e-07\n",
      "Epoch 159/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.3150e-07\n",
      "Epoch 160/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.5022e-07\n",
      "Epoch 161/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.7636e-07\n",
      "Epoch 162/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 6.3989e-07\n",
      "Epoch 163/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.8074e-07\n",
      "Epoch 164/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 6.3905e-07\n",
      "Epoch 165/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 5.7746e-07\n",
      "Epoch 166/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.3129e-07\n",
      "Epoch 167/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.7996e-07\n",
      "Epoch 168/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.1647e-07\n",
      "Epoch 169/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.3314e-07\n",
      "Epoch 170/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.4938e-07\n",
      "Epoch 171/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.5117e-07\n",
      "Epoch 172/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 4.8956e-07\n",
      "Epoch 173/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 5.6886e-07\n",
      "Epoch 174/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 5.1847e-07\n",
      "Epoch 175/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.4262e-07\n",
      "Epoch 176/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.4226e-07\n",
      "Epoch 177/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.1732e-07\n",
      "Epoch 178/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.8007e-07\n",
      "Epoch 179/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.3762e-07\n",
      "Epoch 180/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.4966e-07\n",
      "Epoch 181/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.5542e-07\n",
      "Epoch 182/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.5128e-07\n",
      "Epoch 183/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 4.3343e-07\n",
      "Epoch 184/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.7410e-07\n",
      "Epoch 185/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.1530e-07\n",
      "Epoch 186/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.3424e-07\n",
      "Epoch 187/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.2751e-07\n",
      "Epoch 188/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.1945e-07\n",
      "Epoch 189/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.6732e-07\n",
      "Epoch 190/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 4.5651e-07\n",
      "Epoch 191/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.2358e-07\n",
      "Epoch 192/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.0749e-07\n",
      "Epoch 193/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.9147e-07\n",
      "Epoch 194/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.6185e-07\n",
      "Epoch 195/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.8012e-07\n",
      "Epoch 196/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.4048e-07\n",
      "Epoch 197/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.9959e-07\n",
      "Epoch 198/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.7862e-07\n",
      "Epoch 199/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.3520e-07\n",
      "Epoch 200/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.8104e-07\n",
      "Epoch 201/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.5228e-07\n",
      "Epoch 202/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.4126e-07\n",
      "Epoch 203/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.6208e-07\n",
      "Epoch 204/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.6930e-07\n",
      "Epoch 205/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.1159e-07\n",
      "Epoch 206/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.9709e-07\n",
      "Epoch 207/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.0413e-07\n",
      "Epoch 208/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.2672e-07\n",
      "Epoch 209/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.0148e-07\n",
      "Epoch 210/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.3838e-07\n",
      "Epoch 211/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.1084e-07\n",
      "Epoch 212/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.1076e-07\n",
      "Epoch 213/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.9758e-07\n",
      "Epoch 214/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.7737e-07\n",
      "Epoch 215/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.1070e-07\n",
      "Epoch 216/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.7903e-07\n",
      "Epoch 217/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.7323e-07\n",
      "Epoch 218/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.8900e-07\n",
      "Epoch 219/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.6127e-07\n",
      "Epoch 220/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.6202e-07\n",
      "Epoch 221/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.8873e-07\n",
      "Epoch 222/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.7771e-07\n",
      "Epoch 223/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.9213e-07\n",
      "Epoch 224/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.3854e-07\n",
      "Epoch 225/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.4512e-07\n",
      "Epoch 226/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.3801e-07\n",
      "Epoch 227/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.6561e-07\n",
      "Epoch 228/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.2818e-07\n",
      "Epoch 229/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.2689e-07\n",
      "Epoch 230/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.2799e-07\n",
      "Epoch 231/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.3744e-07\n",
      "Epoch 232/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.1162e-07\n",
      "Epoch 233/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1084e-07\n",
      "Epoch 234/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.2169e-07\n",
      "Epoch 235/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.1557e-07\n",
      "Epoch 236/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.2773e-07\n",
      "Epoch 237/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.0592e-07\n",
      "Epoch 238/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.0493e-07\n",
      "Epoch 239/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 2.1276e-07\n",
      "Epoch 240/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1331e-07\n",
      "Epoch 241/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.9083e-07\n",
      "Epoch 242/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.9735e-07\n",
      "Epoch 243/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.1174e-07\n",
      "Epoch 244/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.9561e-07\n",
      "Epoch 245/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.8689e-07\n",
      "Epoch 246/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.9423e-07\n",
      "Epoch 247/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.9194e-07\n",
      "Epoch 248/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.0294e-07\n",
      "Epoch 249/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.7085e-07\n",
      "Epoch 250/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.9301e-07\n",
      "Epoch 251/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.7080e-07\n",
      "Epoch 252/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.8149e-07\n",
      "Epoch 253/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.0534e-07\n",
      "Epoch 254/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.7079e-07\n",
      "Epoch 255/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.5340e-07\n",
      "Epoch 256/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.7359e-07\n",
      "Epoch 257/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.7089e-07\n",
      "Epoch 258/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.6780e-07\n",
      "Epoch 259/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.6104e-07\n",
      "Epoch 260/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.5246e-07\n",
      "Epoch 261/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.6428e-07\n",
      "Epoch 262/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.4736e-07\n",
      "Epoch 263/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.4069e-07\n",
      "Epoch 264/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3743e-07\n",
      "Epoch 265/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4986e-07\n",
      "Epoch 266/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.4594e-07\n",
      "Epoch 267/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4500e-07\n",
      "Epoch 268/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.4315e-07\n",
      "Epoch 269/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4150e-07\n",
      "Epoch 270/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.5744e-07\n",
      "Epoch 271/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.3306e-07\n",
      "Epoch 272/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.3850e-07\n",
      "Epoch 273/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.4096e-07\n",
      "Epoch 274/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.2604e-07\n",
      "Epoch 275/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.2472e-07\n",
      "Epoch 276/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.3611e-07\n",
      "Epoch 277/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3992e-07\n",
      "Epoch 278/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1965e-07\n",
      "Epoch 279/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3850e-07\n",
      "Epoch 280/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1936e-07\n",
      "Epoch 281/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.2697e-07\n",
      "Epoch 282/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.2673e-07\n",
      "Epoch 283/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.3442e-07\n",
      "Epoch 284/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3148e-07\n",
      "Epoch 285/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.1872e-07\n",
      "Epoch 286/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.2313e-07\n",
      "Epoch 287/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1035e-07\n",
      "Epoch 288/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0992e-07\n",
      "Epoch 289/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.2216e-07\n",
      "Epoch 290/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0588e-07\n",
      "Epoch 291/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.7841e-08\n",
      "Epoch 292/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1188e-07\n",
      "Epoch 293/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0863e-07\n",
      "Epoch 294/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0045e-07\n",
      "Epoch 295/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.0537e-07\n",
      "Epoch 296/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 9.6195e-08\n",
      "Epoch 297/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 9.7487e-08\n",
      "Epoch 298/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.0275e-07\n",
      "Epoch 299/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0141e-07\n",
      "Epoch 300/300\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0127e-07\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(2048,activation='relu',input_shape=(3248,)),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dense(512,activation='relu'),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    keras.layers.Dense(8,activation='softmax'),  # Here 4883 are my unique labels\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train_greater_than_45 = np.array(X_train_greater_than_45)\n",
    "y_train_greater_than_45 = np.array(y_train_greater_than_45)\n",
    "model.fit(X_train_greater_than_45,y_train_greater_than_45,epochs=300,batch_size=64)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "predictions_gt45 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(865, 8)\n",
      "(865, 150)\n"
     ]
    }
   ],
   "source": [
    "predictions_gt45 = np.array(predictions_gt45)\n",
    "predictions_lt45  = np.array(predictions_lt45)\n",
    "print(predictions_gt45.shape)\n",
    "print(predictions_lt45.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n",
      "865\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_lt45= []\n",
    "y_prob_lt45 = []\n",
    "\n",
    "for prediction in predictions_lt45:\n",
    "    y_pred_lt45.append(np.argmax(prediction)) \n",
    "    y_prob_lt45.append(prediction[np.argmax(prediction)])\n",
    "print(len(y_pred_lt45))\n",
    "y_pred_lt45 = np.array(y_pred_lt45)\n",
    "y_prob_l45 = np.array(y_prob_lt45)\n",
    "\n",
    "y_pred_names_lt45 = []\n",
    "for label in y_pred_lt45:\n",
    "    y_pred_names_lt45.append(y_train_labels_to_names_lt45[label])\n",
    "\n",
    "print(len(y_pred_names_lt45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n",
      "865\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_gt45= []\n",
    "y_prob_gt45 = []\n",
    "\n",
    "for prediction in predictions_gt45:\n",
    "    y_pred_gt45.append(np.argmax(prediction)) \n",
    "    y_prob_gt45.append(prediction[np.argmax(prediction)])\n",
    "print(len(y_pred_gt45))\n",
    "y_pred_gt45 = np.array(y_pred_gt45)\n",
    "y_prob_g45 = np.array(y_prob_gt45)\n",
    "\n",
    "y_pred_names_gt45 = []\n",
    "for label in y_pred_gt45:\n",
    "    y_pred_names_gt45.append(y_train_labels_to_names_gt45[label])\n",
    "\n",
    "print(len(y_pred_names_gt45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_names is:  Tony_Blair  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Tony_Blair  or  Jose_Maria_Aznar  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Hans_Blix  and  y_test name is:  Hans_Blix\n",
      "y_pred_names is:  George_W_Bush  or  Mohammad_Khatami  and  y_test name is:  Mohammad_Khatami\n",
      "y_pred_names is:  George_W_Bush  or  George_Robertson  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Paul_Bremer  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  John_Ashcroft  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Eduardo_Duhalde  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Hans_Blix  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  or  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  George_W_Bush  or  John_Kerry  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Nicanor_Duarte_Frutos  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  or  Nestor_Kirchner  and  y_test name is:  Nestor_Kirchner\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Roh_Moo-hyun  and  y_test name is:  Roh_Moo-hyun\n",
      "y_pred_names is:  Tony_Blair  or  Joschka_Fischer  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Nicole_Kidman  and  y_test name is:  Nicole_Kidman\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Sergio_Vieira_De_Mello  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Gerhard_Schroeder  or  George_Robertson  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Colin_Powell  or  Vicente_Fox  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Daschle  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Tony_Blair  or  Naomi_Watts  and  y_test name is:  Naomi_Watts\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  John_Negroponte  and  y_test name is:  John_Negroponte\n",
      "y_pred_names is:  George_W_Bush  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Carlos_Moya  and  y_test name is:  Carlos_Moya\n",
      "y_pred_names is:  George_W_Bush  or  Lindsay_Davenport  and  y_test name is:  Lindsay_Davenport\n",
      "y_pred_names is:  George_W_Bush  or  Lucio_Gutierrez  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jeremy_Greenstock  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Vladimir_Putin  and  y_test name is:  Vladimir_Putin\n",
      "y_pred_names is:  Colin_Powell  or  Roh_Moo-hyun  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  or  John_Allen_Muhammad  and  y_test name is:  John_Allen_Muhammad\n",
      "y_pred_names is:  George_W_Bush  or  Ricardo_Lagos  and  y_test name is:  Ricardo_Lagos\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Hugo_Chavez  or  Mohammad_Khatami  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  Tony_Blair  or  Roh_Moo-hyun  and  y_test name is:  Roh_Moo-hyun\n",
      "y_pred_names is:  George_W_Bush  or  Hans_Blix  and  y_test name is:  Hans_Blix\n",
      "y_pred_names is:  George_W_Bush  or  Joe_Lieberman  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Nestor_Kirchner  and  y_test name is:  Nestor_Kirchner\n",
      "y_pred_names is:  Colin_Powell  or  Silvio_Berlusconi  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  Kofi_Annan  and  y_test name is:  Kofi_Annan\n",
      "y_pred_names is:  Hugo_Chavez  or  Nestor_Kirchner  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  Donald_Rumsfeld  or  John_Howard  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Colin_Powell  or  Gonzalo_Sanchez_de_Lozada  and  y_test name is:  Gonzalo_Sanchez_de_Lozada\n",
      "y_pred_names is:  Hugo_Chavez  or  Lucio_Gutierrez  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  George_W_Bush  or  Jack_Straw  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  Colin_Powell  or  Richard_Myers  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Jean_Chretien  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Donald_Rumsfeld  or  John_Ashcroft  and  y_test name is:  John_Ashcroft\n",
      "y_pred_names is:  George_W_Bush  or  Arnold_Schwarzenegger  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Jack_Straw  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Tony_Blair  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Rudolph_Giuliani  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  Andre_Agassi  and  y_test name is:  Andre_Agassi\n",
      "y_pred_names is:  George_W_Bush  or  John_Ashcroft  and  y_test name is:  John_Ashcroft\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Spencer_Abraham  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Naomi_Watts  and  y_test name is:  Naomi_Watts\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Michael_Bloomberg  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  or  Bill_Gates  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Dick_Cheney  and  y_test name is:  Dick_Cheney\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Tony_Blair  or  Tom_Daschle  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Colin_Powell  or  Pervez_Musharraf  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  or  Nicanor_Duarte_Frutos  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Yoriko_Kawaguchi  and  y_test name is:  Yoriko_Kawaguchi\n",
      "y_pred_names is:  Ariel_Sharon  or  Vladimir_Putin  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  George_W_Bush  or  Abdullah_Gul  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Sergey_Lavrov  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Ariel_Sharon  or  Gonzalo_Sanchez_de_Lozada  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Jennifer_Aniston  and  y_test name is:  Jennifer_Aniston\n",
      "y_pred_names is:  Colin_Powell  or  Kofi_Annan  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Jennifer_Lopez  and  y_test name is:  Jennifer_Lopez\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  Tony_Blair  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Tony_Blair  or  Recep_Tayyip_Erdogan  and  y_test name is:  Recep_Tayyip_Erdogan\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Jiang_Zemin  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Colin_Powell  or  Tom_Ridge  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Tony_Blair  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  Tony_Blair  or  Pierce_Brosnan  and  y_test name is:  Pierce_Brosnan\n",
      "y_pred_names is:  George_W_Bush  or  Paul_Bremer  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Hu_Jintao  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  John_Negroponte  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Jean_Chretien  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Colin_Powell  or  Vladimir_Putin  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Tony_Blair  or  Catherine_Zeta-Jones  and  y_test name is:  Catherine_Zeta-Jones\n",
      "y_pred_names is:  George_W_Bush  or  James_Blake  and  y_test name is:  James_Blake\n",
      "y_pred_names is:  Tony_Blair  or  Vicente_Fox  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Hugo_Chavez  or  George_HW_Bush  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  Tony_Blair  or  Jacques_Chirac  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Michael_Bloomberg  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Luiz_Inacio_Lula_da_Silva\n",
      "y_pred_names is:  Tony_Blair  or  Vladimir_Putin  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Jennifer_Capriati  and  y_test name is:  Jennifer_Capriati\n",
      "y_pred_names is:  Junichiro_Koizumi  or  John_Ashcroft  and  y_test name is:  Junichiro_Koizumi\n",
      "y_pred_names is:  George_W_Bush  or  Bill_Clinton  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Ariel_Sharon  or  Kofi_Annan  and  y_test name is:  Kofi_Annan\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Jennifer_Capriati  and  y_test name is:  Jennifer_Capriati\n",
      "y_pred_names is:  Tony_Blair  or  John_Negroponte  and  y_test name is:  John_Negroponte\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Vladimir_Putin  and  y_test name is:  Junichiro_Koizumi\n",
      "y_pred_names is:  George_W_Bush  or  Vicente_Fox  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  George_Robertson  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Vladimir_Putin  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Kofi_Annan  and  y_test name is:  Kofi_Annan\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Charest  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Kofi_Annan  and  y_test name is:  Kofi_Annan\n",
      "y_pred_names is:  George_W_Bush  or  David_Beckham  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Tony_Blair  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  Ariel_Sharon  or  Silvio_Berlusconi  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Colin_Powell  or  Kofi_Annan  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Juan_Carlos_Ferrero  and  y_test name is:  Juan_Carlos_Ferrero\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Arnold_Schwarzenegger  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Hamid_Karzai  and  y_test name is:  Hamid_Karzai\n",
      "y_pred_names is:  Tony_Blair  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Jack_Straw  and  y_test name is:  Jack_Straw\n",
      "y_pred_names is:  George_W_Bush  or  Paul_Burrell  and  y_test name is:  Paul_Burrell\n",
      "y_pred_names is:  George_W_Bush  or  Lleyton_Hewitt  and  y_test name is:  Lleyton_Hewitt\n",
      "y_pred_names is:  George_W_Bush  or  Kim_Ryong-sung  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Queen_Elizabeth_II  and  y_test name is:  Queen_Elizabeth_II\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Hans_Blix  and  y_test name is:  Hans_Blix\n",
      "y_pred_names is:  Tony_Blair  or  Tom_Daschle  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Hugo_Chavez  or  Jiang_Zemin  and  y_test name is:  Jiang_Zemin\n",
      "y_pred_names is:  Hugo_Chavez  or  Winona_Ryder  and  y_test name is:  Winona_Ryder\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jack_Straw  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Guillermo_Coria  and  y_test name is:  Guillermo_Coria\n",
      "y_pred_names is:  Colin_Powell  or  Trent_Lott  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Vladimir_Putin  and  y_test name is:  Vladimir_Putin\n",
      "y_pred_names is:  Colin_Powell  or  Hans_Blix  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  John_Negroponte  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  Kofi_Annan  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  George_W_Bush  or  Saddam_Hussein  and  y_test name is:  Saddam_Hussein\n",
      "y_pred_names is:  Colin_Powell  or  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  George_W_Bush  or  Bill_Clinton  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Alejandro_Toledo  and  y_test name is:  Alejandro_Toledo\n",
      "y_pred_names is:  George_W_Bush  or  Andre_Agassi  and  y_test name is:  Andre_Agassi\n",
      "y_pred_names is:  Hugo_Chavez  or  Saddam_Hussein  and  y_test name is:  Saddam_Hussein\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Charest  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Juan_Carlos_Ferrero  and  y_test name is:  Juan_Carlos_Ferrero\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Vicente_Fox  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Jennifer_Capriati  and  y_test name is:  Junichiro_Koizumi\n",
      "y_pred_names is:  Tony_Blair  or  Tang_Jiaxuan  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Colin_Powell  or  Venus_Williams  and  y_test name is:  Venus_Williams\n",
      "y_pred_names is:  Hugo_Chavez  or  Taha_Yassin_Ramadan  and  y_test name is:  Taha_Yassin_Ramadan\n",
      "y_pred_names is:  George_W_Bush  or  Mohammed_Al-Douri  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Vladimir_Putin  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Mahmoud_Abbas  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  or  Jeb_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jeb_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Queen_Elizabeth_II  and  y_test name is:  Queen_Elizabeth_II\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Winona_Ryder  and  y_test name is:  Winona_Ryder\n",
      "y_pred_names is:  George_W_Bush  or  James_Blake  and  y_test name is:  James_Blake\n",
      "y_pred_names is:  George_W_Bush  or  Amelie_Mauresmo  and  y_test name is:  Amelie_Mauresmo\n",
      "y_pred_names is:  Colin_Powell  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  Tony_Blair  or  Nicole_Kidman  and  y_test name is:  Nicole_Kidman\n",
      "y_pred_names is:  George_W_Bush  or  Lance_Armstrong  and  y_test name is:  Lance_Armstrong\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Tang_Jiaxuan  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  or  Arnold_Schwarzenegger  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Luiz_Inacio_Lula_da_Silva\n",
      "y_pred_names is:  Tony_Blair  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Atal_Bihari_Vajpayee  and  y_test name is:  Atal_Bihari_Vajpayee\n",
      "y_pred_names is:  George_W_Bush  or  John_Kerry  and  y_test name is:  John_Kerry\n",
      "y_pred_names is:  Hugo_Chavez  or  Nicanor_Duarte_Frutos  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  George_W_Bush  or  Rudolph_Giuliani  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Vladimir_Putin  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Jiang_Zemin  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Tony_Blair  or  Laura_Bush  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Amelie_Mauresmo  and  y_test name is:  Amelie_Mauresmo\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Megawati_Sukarnoputri  and  y_test name is:  Megawati_Sukarnoputri\n",
      "y_pred_names is:  Tony_Blair  or  Yoriko_Kawaguchi  and  y_test name is:  Yoriko_Kawaguchi\n",
      "y_pred_names is:  Ariel_Sharon  or  John_Howard  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Jacques_Chirac  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Tony_Blair  or  Gordon_Brown  and  y_test name is:  Gordon_Brown\n",
      "y_pred_names is:  George_W_Bush  or  Bill_Clinton  and  y_test name is:  Bill_Clinton\n",
      "y_pred_names is:  Tony_Blair  or  Michael_Bloomberg  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Andre_Agassi  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Megawati_Sukarnoputri  and  y_test name is:  Megawati_Sukarnoputri\n",
      "y_pred_names is:  George_W_Bush  or  Nicanor_Duarte_Frutos  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Abdullah_Gul  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Gerhard_Schroeder  or  John_Ashcroft  and  y_test name is:  John_Ashcroft\n",
      "y_pred_names is:  George_W_Bush  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Luiz_Inacio_Lula_da_Silva\n",
      "y_pred_names is:  Colin_Powell  or  Bill_Clinton  and  y_test name is:  Bill_Clinton\n",
      "y_pred_names is:  George_W_Bush  or  Abdullah_Gul  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Bill_Clinton  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Tony_Blair  or  Jack_Straw  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Jennifer_Capriati  and  y_test name is:  Jennifer_Capriati\n",
      "y_pred_names is:  George_W_Bush  or  Gloria_Macapagal_Arroyo  and  y_test name is:  Gloria_Macapagal_Arroyo\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Roh_Moo-hyun  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  George_W_Bush  or  Tiger_Woods  and  y_test name is:  Tiger_Woods\n",
      "y_pred_names is:  Tony_Blair  or  Gloria_Macapagal_Arroyo  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Colin_Powell  or  Tang_Jiaxuan  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Harrison_Ford  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  Ariel_Sharon  or  Atal_Bihari_Vajpayee  and  y_test name is:  Atal_Bihari_Vajpayee\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Alvaro_Uribe  and  y_test name is:  Alvaro_Uribe\n",
      "y_pred_names is:  Tony_Blair  or  Igor_Ivanov  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Paul_Bremer  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  George_W_Bush  or  Mahathir_Mohamad  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Juan_Carlos_Ferrero  and  y_test name is:  Juan_Carlos_Ferrero\n",
      "y_pred_names is:  Tony_Blair  or  Lindsay_Davenport  and  y_test name is:  Lindsay_Davenport\n",
      "y_pred_names is:  George_W_Bush  or  Gray_Davis  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Walter_Mondale  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Ariel_Sharon  or  Igor_Ivanov  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Colin_Powell  or  Lucio_Gutierrez  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Arnold_Schwarzenegger  and  y_test name is:  Arnold_Schwarzenegger\n",
      "y_pred_names is:  Tony_Blair  or  John_Bolton  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Nestor_Kirchner  and  y_test name is:  Nestor_Kirchner\n",
      "y_pred_names is:  Tony_Blair  or  Salma_Hayek  and  y_test name is:  Salma_Hayek\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Andre_Agassi  and  y_test name is:  Junichiro_Koizumi\n",
      "y_pred_names is:  George_W_Bush  or  Spencer_Abraham  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Kofi_Annan  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  or  Muhammad_Ali  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  George_W_Bush  or  Paul_Wolfowitz  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Ariel_Sharon  or  John_Paul_II  and  y_test name is:  John_Paul_II\n",
      "y_pred_names is:  George_W_Bush  or  Vladimir_Putin  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Silvio_Berlusconi  and  y_test name is:  Silvio_Berlusconi\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  Colin_Powell  or  John_Snow  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  George_W_Bush  or  Vladimir_Putin  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Guillermo_Coria  and  y_test name is:  Guillermo_Coria\n",
      "y_pred_names is:  Colin_Powell  or  Roh_Moo-hyun  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  John_Bolton  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Silvio_Berlusconi  and  y_test name is:  Silvio_Berlusconi\n",
      "y_pred_names is:  Ariel_Sharon  or  Igor_Ivanov  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  George_W_Bush  or  Lleyton_Hewitt  and  y_test name is:  Lleyton_Hewitt\n",
      "y_pred_names is:  George_W_Bush  or  Bill_Gates  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Tony_Blair  or  Anna_Kournikova  and  y_test name is:  Anna_Kournikova\n",
      "y_pred_names is:  Donald_Rumsfeld  or  George_Robertson  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Hugo_Chavez  or  Jackie_Chan  and  y_test name is:  Jackie_Chan\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Richard_Gephardt  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  or  Trent_Lott  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Hugo_Chavez  or  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  Gerhard_Schroeder  or  George_Robertson  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Roh_Moo-hyun  and  y_test name is:  Roh_Moo-hyun\n",
      "y_pred_names is:  Ariel_Sharon  or  Michael_Bloomberg  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  George_W_Bush  or  David_Beckham  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Luiz_Inacio_Lula_da_Silva\n",
      "y_pred_names is:  George_W_Bush  or  Muhammad_Ali  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Dick_Cheney  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Hugo_Chavez  or  Hamid_Karzai  and  y_test name is:  Hamid_Karzai\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Gloria_Macapagal_Arroyo  and  y_test name is:  Gloria_Macapagal_Arroyo\n",
      "y_pred_names is:  George_W_Bush  or  John_Kerry  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Ariel_Sharon  or  Saddam_Hussein  and  y_test name is:  Saddam_Hussein\n",
      "y_pred_names is:  Colin_Powell  or  Jack_Straw  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Paul_Burrell  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Richard_Myers  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  or  John_Allen_Muhammad  and  y_test name is:  John_Allen_Muhammad\n",
      "y_pred_names is:  Colin_Powell  or  John_Ashcroft  and  y_test name is:  John_Ashcroft\n",
      "y_pred_names is:  Tony_Blair  or  Megawati_Sukarnoputri  and  y_test name is:  Megawati_Sukarnoputri\n",
      "y_pred_names is:  George_W_Bush  or  Paul_Bremer  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Arnold_Schwarzenegger  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Walter_Mondale  and  y_test name is:  Walter_Mondale\n",
      "y_pred_names is:  Colin_Powell  or  Arnold_Schwarzenegger  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Jack_Straw  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Tony_Blair  or  Guillermo_Coria  and  y_test name is:  Guillermo_Coria\n",
      "y_pred_names is:  Tony_Blair  or  John_Snow  and  y_test name is:  John_Snow\n",
      "y_pred_names is:  Colin_Powell  or  Paul_Wolfowitz  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  John_Ashcroft  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Hugo_Chavez  or  Andre_Agassi  and  y_test name is:  Andre_Agassi\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Sergio_Vieira_De_Mello  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Gerhard_Schroeder  or  John_Ashcroft  and  y_test name is:  John_Ashcroft\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Tom_Hanks  and  y_test name is:  Junichiro_Koizumi\n",
      "y_pred_names is:  George_W_Bush  or  John_Ashcroft  and  y_test name is:  John_Ashcroft\n",
      "y_pred_names is:  George_W_Bush  or  Jennifer_Capriati  and  y_test name is:  Jennifer_Capriati\n",
      "y_pred_names is:  Colin_Powell  or  James_Kelly  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Michael_Bloomberg  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Donald_Rumsfeld  or  John_Paul_II  and  y_test name is:  John_Paul_II\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Tom_Ridge  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Colin_Powell  or  Arnold_Schwarzenegger  and  y_test name is:  Arnold_Schwarzenegger\n",
      "y_pred_names is:  George_W_Bush  or  John_Ashcroft  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Nestor_Kirchner  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Gloria_Macapagal_Arroyo  and  y_test name is:  Gloria_Macapagal_Arroyo\n",
      "y_pred_names is:  Hugo_Chavez  or  Megawati_Sukarnoputri  and  y_test name is:  Megawati_Sukarnoputri\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Luiz_Inacio_Lula_da_Silva\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Michael_Bloomberg  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Tony_Blair  or  Britney_Spears  and  y_test name is:  Britney_Spears\n",
      "y_pred_names is:  Tony_Blair  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Tony_Blair  or  Bill_Simon  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Tony_Blair  or  Meryl_Streep  and  y_test name is:  Meryl_Streep\n",
      "y_pred_names is:  Colin_Powell  or  Jeb_Bush  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  or  Mahmoud_Abbas  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  George_W_Bush  or  Carlos_Moya  and  y_test name is:  Carlos_Moya\n",
      "y_pred_names is:  Colin_Powell  or  Hans_Blix  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  Tom_Ridge\n",
      "y_pred_names is:  Colin_Powell  or  Andre_Agassi  and  y_test name is:  Andre_Agassi\n",
      "y_pred_names is:  George_W_Bush  or  Roh_Moo-hyun  and  y_test name is:  Roh_Moo-hyun\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Hu_Jintao  and  y_test name is:  Hu_Jintao\n",
      "y_pred_names is:  Gerhard_Schroeder  or  David_Beckham  and  y_test name is:  David_Beckham\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Daschle  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Vladimir_Putin  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  or  John_Ashcroft  and  y_test name is:  John_Ashcroft\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Pete_Sampras  and  y_test name is:  Pete_Sampras\n",
      "y_pred_names is:  George_W_Bush  or  Michael_Bloomberg  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Luiz_Inacio_Lula_da_Silva\n",
      "y_pred_names is:  Tony_Blair  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  George_W_Bush  or  David_Beckham  and  y_test name is:  David_Beckham\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Recep_Tayyip_Erdogan  and  y_test name is:  Recep_Tayyip_Erdogan\n",
      "y_pred_names is:  George_W_Bush  or  Gloria_Macapagal_Arroyo  and  y_test name is:  Gloria_Macapagal_Arroyo\n",
      "y_pred_names is:  Hugo_Chavez  or  Fidel_Castro  and  y_test name is:  Fidel_Castro\n",
      "y_pred_names is:  George_W_Bush  or  Renee_Zellweger  and  y_test name is:  Renee_Zellweger\n",
      "y_pred_names is:  George_W_Bush  or  Trent_Lott  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  Colin_Powell  or  Alejandro_Toledo  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  George_Robertson  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Jason_Kidd  and  y_test name is:  Jason_Kidd\n",
      "y_pred_names is:  George_W_Bush  or  John_Paul_II  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  George_W_Bush  or  Michael_Bloomberg  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Ariel_Sharon  or  Vladimir_Putin  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Hugo_Chavez  or  Tiger_Woods  and  y_test name is:  Tiger_Woods\n",
      "y_pred_names is:  Tony_Blair  or  James_Blake  and  y_test name is:  James_Blake\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Ariel_Sharon  or  Jacques_Chirac  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Tony_Blair  or  Bill_Gates  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  Hugo_Chavez  or  Jacques_Chirac  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Eduardo_Duhalde  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Gordon_Brown  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Tony_Blair  or  Tom_Daschle  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Rudolph_Giuliani  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Hugo_Chavez  or  Jackie_Chan  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  George_W_Bush  or  Richard_Gephardt  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Gerhard_Schroeder  or  George_Robertson  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Colin_Powell  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Jack_Straw  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  George_W_Bush  or  Carlos_Moya  and  y_test name is:  Carlos_Moya\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Hu_Jintao  and  y_test name is:  Hu_Jintao\n",
      "y_pred_names is:  George_W_Bush  or  Fidel_Castro  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  George_W_Bush  or  Vicente_Fox  and  y_test name is:  Vicente_Fox\n",
      "y_pred_names is:  Hugo_Chavez  or  Sergio_Vieira_De_Mello  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  Colin_Powell  or  Michael_Bloomberg  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Lleyton_Hewitt  and  y_test name is:  Lleyton_Hewitt\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Jennifer_Capriati  and  y_test name is:  Jennifer_Capriati\n",
      "y_pred_names is:  Ariel_Sharon  or  John_Snow  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Jean_Chretien  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Luiz_Inacio_Lula_da_Silva\n",
      "y_pred_names is:  George_W_Bush  or  Lleyton_Hewitt  and  y_test name is:  Lleyton_Hewitt\n",
      "y_pred_names is:  Hugo_Chavez  or  Andre_Agassi  and  y_test name is:  Andre_Agassi\n",
      "y_pred_names is:  Hugo_Chavez  or  Jiang_Zemin  and  y_test name is:  Jiang_Zemin\n",
      "y_pred_names is:  Colin_Powell  or  Tang_Jiaxuan  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  Naomi_Watts  and  y_test name is:  Naomi_Watts\n",
      "y_pred_names is:  Hugo_Chavez  or  Michael_Schumacher  and  y_test name is:  Michael_Schumacher\n",
      "y_pred_names is:  George_W_Bush  or  Lindsay_Davenport  and  y_test name is:  Lindsay_Davenport\n",
      "y_pred_names is:  Tony_Blair  or  Tommy_Franks  and  y_test name is:  Tommy_Franks\n",
      "y_pred_names is:  Tony_Blair  or  Saddam_Hussein  and  y_test name is:  Saddam_Hussein\n",
      "y_pred_names is:  Gerhard_Schroeder  or  John_Snow  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  George_W_Bush  or  Gray_Davis  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Hugo_Chavez  or  Muhammad_Ali  and  y_test name is:  Muhammad_Ali\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Naomi_Watts  and  y_test name is:  Naomi_Watts\n",
      "y_pred_names is:  George_W_Bush  or  Nestor_Kirchner  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  John_Negroponte  and  y_test name is:  John_Negroponte\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Roh_Moo-hyun  and  y_test name is:  Roh_Moo-hyun\n",
      "y_pred_names is:  Colin_Powell  or  John_Snow  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Donald_Rumsfeld  or  John_Bolton  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Colin_Powell  or  Arnold_Schwarzenegger  and  y_test name is:  Arnold_Schwarzenegger\n",
      "y_pred_names is:  George_W_Bush  or  Lleyton_Hewitt  and  y_test name is:  Lleyton_Hewitt\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Roh_Moo-hyun  and  y_test name is:  Roh_Moo-hyun\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Halle_Berry  and  y_test name is:  Halle_Berry\n",
      "y_pred_names is:  Junichiro_Koizumi  or  John_Kerry  and  y_test name is:  Junichiro_Koizumi\n",
      "y_pred_names is:  Hugo_Chavez  or  Roh_Moo-hyun  and  y_test name is:  Roh_Moo-hyun\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Alejandro_Toledo  and  y_test name is:  Alejandro_Toledo\n",
      "y_pred_names is:  George_W_Bush  or  Dick_Cheney  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Bill_McBride  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  or  Nicanor_Duarte_Frutos  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Kofi_Annan  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Vicente_Fox  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Jiang_Zemin  and  y_test name is:  Jiang_Zemin\n",
      "y_pred_names is:  Hugo_Chavez  or  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  Colin_Powell  or  John_Snow  and  y_test name is:  John_Snow\n",
      "y_pred_names is:  Colin_Powell  or  Michael_Bloomberg  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Colin_Powell  or  Pervez_Musharraf  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Junichiro_Koizumi  or  John_Kerry  and  y_test name is:  John_Kerry\n",
      "y_pred_names is:  Hugo_Chavez  or  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Gray_Davis  and  y_test name is:  Gray_Davis\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Lleyton_Hewitt  and  y_test name is:  Lleyton_Hewitt\n",
      "y_pred_names is:  George_W_Bush  or  Harrison_Ford  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  John_Ashcroft  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  or  Tom_Hanks  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  or  Michael_Bloomberg  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Colin_Powell  or  Jean_Charest  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  Tony_Blair  or  Tom_Daschle  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  or  Bill_Simon  and  y_test name is:  Bill_Simon\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Hans_Blix  and  y_test name is:  Hans_Blix\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Abdullah_Gul  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Ariel_Sharon  or  Kofi_Annan  and  y_test name is:  Kofi_Annan\n",
      "y_pred_names is:  Colin_Powell  or  Michael_Bloomberg  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Nicanor_Duarte_Frutos  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Paul_Wolfowitz  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Javier_Solana  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  or  Fidel_Castro  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  or  Tom_Ridge  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Colin_Powell  or  Hu_Jintao  and  y_test name is:  Hu_Jintao\n",
      "y_pred_names is:  Tony_Blair  or  Sergey_Lavrov  and  y_test name is:  Sergey_Lavrov\n",
      "y_pred_names is:  Gerhard_Schroeder  or  Luiz_Inacio_Lula_da_Silva  and  y_test name is:  Luiz_Inacio_Lula_da_Silva\n",
      "y_pred_names is:  Colin_Powell  or  Jacques_Chirac  and  y_test name is:  Jacques_Chirac\n",
      "y_pred_names is:  Junichiro_Koizumi  or  Roh_Moo-hyun  and  y_test name is:  Junichiro_Koizumi\n",
      "y_pred_names is:  George_W_Bush  or  Jose_Maria_Aznar  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  or  Tom_Ridge  and  y_test name is:  George_W_Bush\n",
      "\n",
      "\n",
      "Accuracy is this:  0.48554913294797686\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y_pred_names_lt45)):\n",
    "    # if y_prob_gt45 > y_prob_lt45:\n",
    "    pred_name1 = y_pred_names_gt45[i]\n",
    "    # else:\n",
    "    pred_name2 = y_pred_names_lt45[i]\n",
    "        \n",
    "    if pred_name1 == y_test[i] or pred_name2 == y_test[i]:  \n",
    "        print(\"y_pred_names is: \",pred_name1,\" or \",pred_name2,\" and \",\"y_test name is: \",y_test[i])\n",
    "        count+=1\n",
    "\n",
    "accuracy = count/865\n",
    "print(\"\\n\\nAccuracy is this: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapping Back The Predicted Values To The Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5  90  29 110  98  35  64   4   2   5 106  20  41  73  38  34  75   5\n",
      "  20  77  62 117  65  22 101  93  20 135  70  55  78  85  98  46   5  31\n",
      "  55  20   5 125  72  21  20  46  27   5  20  35  30   4  20  51  74 131\n",
      "  55  86  74   5  62  85  14  41  16   8  40   5 101  48  98 155   5 107\n",
      "   5   5  35  40  28   1  11 117  56 156  71  20  77  38   8   5 149 155\n",
      "  54 121   5 106  77   1 121 155  17  89 141  98  83  25  65  54  17  60\n",
      " 130  40  72  77  17  58  46   5  22  62  20   9  88  46  20  77  89 123\n",
      "   1  92   5  74   8  28  94  86  43  20  54  63  20 107  35  88 131 119\n",
      " 147  74 151  82  77  20  20  20  28  24 117 117 149  35  77   0  24  17\n",
      "  36  74   1  35  48  25  35  27  28 145  43   5 105  46  60 147  90  46\n",
      "  55 117 108  67   5 107  21 110  38  16   8  46 117  98   5  25   5  13\n",
      "  38   8 132   8  33  46  21 122   0 113  88   5  41  89   8  79 121  35\n",
      "  66 148  34  29 106  55 106   6   5  20   5 110   8  35  66   5  94  62\n",
      "  22  20  74  20  90   1 140  27   5   8   5  97  43 117  46  34   5  59\n",
      "  10   8 120  74 124  49  41  38  74  79  29  28   5 157  46  53   8 118\n",
      "   9  77  28 121  74  46 119  23  89  20 110  22  16  63  46  21   8   1\n",
      "  41  38 151   8  46  41   5   7   5  38  54 156  46  65   1  27  38  19\n",
      "  93  22  87   9 105  50  41   5 107  20  17  66   2 116   5   5   8  63\n",
      "  35 150  24  75  46  21  48  91 151 114   9  77  20  11   5  71  88  74\n",
      "  86 151  20   5   1  35  75  46   8  27  11  55   8  41  50  35  36  22\n",
      " 151 106 148  20  20   5  27 150 150 134  46  23   8   5 107  20   5 118\n",
      " 119  34   5  20  46   5  46  20  19  20  46   5  55  82  16  94 123  29\n",
      "  14  20  53  90  35  60  46  26   8  26  46  32  98  63  46   8   5   5\n",
      "  21  42  98 132  21  43  39  20   5   5  54  41  22   1 143 121  15  57\n",
      " 116  44  29  19  19  22  73   4  72 114   5  20  35   8   5   8   5   8\n",
      "  32  64  26 122  29  20 109   8  16   5   5 102 147  64  74 121  69  46\n",
      "  20   5  49   8   1 122  92  74  55   5  16 119 137 106  72  20  74   1\n",
      "   5   3  21  38  20   5 117  80  55 146  35  14   5  68  55  46  19  69\n",
      "   8  98  55  79 114   5  20 111  55  54  58  21   8   8   4   5  29 118\n",
      "  46  46  54   8  37  11   4   5  86  90  40  34   5  46 117   5  20  28\n",
      "  41  35   5  38  22  20  20  43  20   5  37   8  16 117   5  55  55   5\n",
      "  18  20   8   5 104  55 147  74   5  64 119   5 155  74   8  29 111   8\n",
      "   8  46 106 109 137 134   5   5  45  31  55   2   8  13  82 150  69 140\n",
      "  55  74   1 102  28  20 136 117 119  60  29  70  80  54  79 121  34 118\n",
      "  62 109  49  44   4 127   8  62  46 143  47  67  80  42 153   5   5  39\n",
      "  77   8  98  12   0  16   5  85  21  44   8  62 112  37 114 150  17   5\n",
      "   4   5  72  39  98  22 133 117  77   8  27  77 119  41  35  46  25  45\n",
      "  74  35 104  32   8 117  52   5   8   5  12  51   8  57  49  41  25 115\n",
      "  67   5   4  55  50 121   5  29   5  26  57  79   5  22 152 137   8  22\n",
      " 119  35  20  20 102  88 119  73  89 114 156 108   5  46  63 157  21  20\n",
      "  55   5  77 152  75 120  41  73   5  79   9  19   5 104  11  46 108   8\n",
      "  35   8  36  42   5   6   5   5  43  51  66   5   5  55   4   8  41 134\n",
      " 113  35  43  79 127  76  91   8  30   9  26  98  44  20  23  40   8 133\n",
      "  74  46  46   5  71  20   5 106 120   5  55  55  39 116  46  21  46  75\n",
      "  89   8  33   5  20  67  65  34 101  71 117 132  21  38  27  27  89  55\n",
      "  57   3   5  91  67  46  22  55  55 108  10  66  20   8  92  70  28  10\n",
      " 151  54  55 140  46  20  55 156  93  55   5 114 132  68  35   5 131  55\n",
      "  10  26 145  64  59  16 109  22   8   5  43 119  20  94  41   5  54  42\n",
      "  38]\n"
     ]
    }
   ],
   "source": [
    "y_pred_10 = []\n",
    "for prediction in predictions_10:\n",
    "    y_pred_10.append(np.argmax(prediction))\n",
    "    \n",
    "y_pred_10 = np.array(y_pred_10)\n",
    "print(y_pred_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['George_W_Bush' 'Luiz_Inacio_Lula_da_Silva' 'Alejandro_Toledo'\n",
      " 'Angelina_Jolie' 'John_Ashcroft' 'Hugo_Chavez' 'Jack_Straw'\n",
      " 'Renee_Zellweger' 'Tom_Daschle' 'George_W_Bush' 'Nestor_Kirchner'\n",
      " 'Colin_Powell' 'Andre_Agassi' 'Wen_Jiabao' 'Alvaro_Uribe'\n",
      " 'Junichiro_Koizumi' 'Lindsay_Davenport' 'George_W_Bush' 'Colin_Powell'\n",
      " 'Kofi_Annan' 'Winona_Ryder' 'Laura_Bush' 'John_Kerry' 'Jean_Chretien'\n",
      " 'Trent_Lott' 'Amelie_Mauresmo' 'Colin_Powell' 'Mike_Weir' 'Jiri_Novak'\n",
      " 'Donald_Rumsfeld' 'Jean_Charest' 'Bill_Simon' 'John_Ashcroft'\n",
      " 'Gerhard_Schroeder' 'George_W_Bush' 'Queen_Elizabeth_II'\n",
      " 'Donald_Rumsfeld' 'Colin_Powell' 'George_W_Bush' 'Lucio_Gutierrez'\n",
      " 'Salma_Hayek' 'Serena_Williams' 'Colin_Powell' 'Gerhard_Schroeder'\n",
      " 'Lleyton_Hewitt' 'George_W_Bush' 'Colin_Powell' 'Hugo_Chavez'\n",
      " 'Julie_Gerberding' 'Renee_Zellweger' 'Colin_Powell' 'Tang_Jiaxuan'\n",
      " 'Ariel_Sharon' 'Jackie_Chan' 'Donald_Rumsfeld' 'Spencer_Abraham'\n",
      " 'Ariel_Sharon' 'George_W_Bush' 'Winona_Ryder' 'Bill_Simon'\n",
      " 'Atal_Bihari_Vajpayee' 'Andre_Agassi' 'Jennifer_Capriati' 'Tony_Blair'\n",
      " 'Lance_Armstrong' 'George_W_Bush' 'Trent_Lott' 'Hans_Blix'\n",
      " 'John_Ashcroft' 'John_Allen_Muhammad' 'George_W_Bush'\n",
      " 'Nicanor_Duarte_Frutos' 'George_W_Bush' 'George_W_Bush' 'Hugo_Chavez'\n",
      " 'Lance_Armstrong' 'Megawati_Sukarnoputri' 'Silvio_Berlusconi'\n",
      " 'Hamid_Karzai' 'Laura_Bush' 'Ann_Veneman' 'Ian_Thorpe' 'Tom_Ridge'\n",
      " 'Colin_Powell' 'Kofi_Annan' 'Alvaro_Uribe' 'Tony_Blair' 'George_W_Bush'\n",
      " 'Jennifer_Garner' 'John_Allen_Muhammad' 'Jacques_Chirac'\n",
      " 'Guillermo_Coria' 'George_W_Bush' 'Nestor_Kirchner' 'Kofi_Annan'\n",
      " 'Silvio_Berlusconi' 'Guillermo_Coria' 'John_Allen_Muhammad'\n",
      " 'Mahmoud_Abbas' 'Vladimir_Putin' 'Gordon_Brown' 'John_Ashcroft'\n",
      " 'John_Negroponte' 'Michael_Bloomberg' 'John_Kerry' 'Jacques_Chirac'\n",
      " 'Mahmoud_Abbas' 'Joe_Lieberman' 'Gonzalo_Sanchez_de_Lozada'\n",
      " 'Lance_Armstrong' 'Salma_Hayek' 'Kofi_Annan' 'Mahmoud_Abbas'\n",
      " 'Venus_Williams' 'Gerhard_Schroeder' 'George_W_Bush' 'Jean_Chretien'\n",
      " 'Winona_Ryder' 'Colin_Powell' 'David_Beckham' 'Sergey_Lavrov'\n",
      " 'Gerhard_Schroeder' 'Colin_Powell' 'Kofi_Annan' 'Vladimir_Putin'\n",
      " 'Yoriko_Kawaguchi' 'Silvio_Berlusconi' 'Jason_Kidd' 'George_W_Bush'\n",
      " 'Ariel_Sharon' 'Tony_Blair' 'Megawati_Sukarnoputri' 'Rudolph_Giuliani'\n",
      " 'Spencer_Abraham' 'Nicole_Kidman' 'Colin_Powell' 'Jacques_Chirac'\n",
      " 'Jeremy_Greenstock' 'Colin_Powell' 'Nicanor_Duarte_Frutos' 'Hugo_Chavez'\n",
      " 'Sergey_Lavrov' 'Jackie_Chan' 'Recep_Tayyip_Erdogan'\n",
      " 'Sergio_Vieira_De_Mello' 'Ariel_Sharon' 'Halle_Berry' 'Carlos_Menem'\n",
      " 'Kofi_Annan' 'Colin_Powell' 'Colin_Powell' 'Colin_Powell'\n",
      " 'Megawati_Sukarnoputri' 'Norah_Jones' 'Laura_Bush' 'Laura_Bush'\n",
      " 'Jennifer_Garner' 'Hugo_Chavez' 'Kofi_Annan' 'Tom_Hanks' 'Norah_Jones'\n",
      " 'Mahmoud_Abbas' 'Charles_Moose' 'Ariel_Sharon' 'Silvio_Berlusconi'\n",
      " 'Hugo_Chavez' 'Hans_Blix' 'Michael_Bloomberg' 'Hugo_Chavez'\n",
      " 'Lleyton_Hewitt' 'Megawati_Sukarnoputri' 'Pierce_Brosnan' 'Nicole_Kidman'\n",
      " 'George_W_Bush' 'Anna_Kournikova' 'Gerhard_Schroeder' 'Joe_Lieberman'\n",
      " 'Sergio_Vieira_De_Mello' 'Luiz_Inacio_Lula_da_Silva' 'Gerhard_Schroeder'\n",
      " 'Donald_Rumsfeld' 'Laura_Bush' 'Joschka_Fischer' 'Harrison_Ford'\n",
      " 'George_W_Bush' 'Nicanor_Duarte_Frutos' 'Serena_Williams'\n",
      " 'Angelina_Jolie' 'Alvaro_Uribe' 'Jennifer_Capriati' 'Tony_Blair'\n",
      " 'Gerhard_Schroeder' 'Laura_Bush' 'John_Ashcroft' 'George_W_Bush'\n",
      " 'Michael_Bloomberg' 'George_W_Bush' 'John_Bolton' 'Alvaro_Uribe'\n",
      " 'Tony_Blair' 'Dominique_de_Villepin' 'Tony_Blair' 'Naomi_Watts'\n",
      " 'Gerhard_Schroeder' 'Serena_Williams' 'Mahathir_Mohamad' 'Tom_Hanks'\n",
      " 'Paradorn_Srichaphan' 'Sergey_Lavrov' 'George_W_Bush' 'Andre_Agassi'\n",
      " 'Vladimir_Putin' 'Tony_Blair' 'Abdullah_Gul' 'Guillermo_Coria'\n",
      " 'Hugo_Chavez' 'Fidel_Castro' 'Walter_Mondale' 'Junichiro_Koizumi'\n",
      " 'Alejandro_Toledo' 'Nestor_Kirchner' 'Donald_Rumsfeld' 'Nestor_Kirchner'\n",
      " 'John_Paul_II' 'George_W_Bush' 'Colin_Powell' 'George_W_Bush'\n",
      " 'Angelina_Jolie' 'Tony_Blair' 'Hugo_Chavez' 'Fidel_Castro'\n",
      " 'George_W_Bush' 'Rudolph_Giuliani' 'Winona_Ryder' 'Jean_Chretien'\n",
      " 'Colin_Powell' 'Ariel_Sharon' 'Colin_Powell' 'Luiz_Inacio_Lula_da_Silva'\n",
      " 'Silvio_Berlusconi' 'Britney_Spears' 'Lleyton_Hewitt' 'George_W_Bush'\n",
      " 'Tony_Blair' 'George_W_Bush' 'Jiang_Zemin' 'Nicole_Kidman' 'Laura_Bush'\n",
      " 'Gerhard_Schroeder' 'Junichiro_Koizumi' 'George_W_Bush' 'John_Howard'\n",
      " 'Jose_Maria_Aznar' 'Tony_Blair' 'Carlos_Moya' 'Ariel_Sharon'\n",
      " 'Ari_Fleischer' 'Roger_Federer' 'Andre_Agassi' 'Alvaro_Uribe'\n",
      " 'Ariel_Sharon' 'Abdullah_Gul' 'Alejandro_Toledo' 'Megawati_Sukarnoputri'\n",
      " 'George_W_Bush' 'Michael_Schumacher' 'Gerhard_Schroeder'\n",
      " 'Eduardo_Duhalde' 'Tony_Blair' 'Condoleezza_Rice' 'David_Beckham'\n",
      " 'Kofi_Annan' 'Megawati_Sukarnoputri' 'Guillermo_Coria' 'Ariel_Sharon'\n",
      " 'Gerhard_Schroeder' 'Recep_Tayyip_Erdogan' 'Dick_Cheney' 'Vladimir_Putin'\n",
      " 'Colin_Powell' 'Angelina_Jolie' 'Jean_Chretien' 'Jennifer_Capriati'\n",
      " 'Jeremy_Greenstock' 'Gerhard_Schroeder' 'Serena_Williams' 'Tony_Blair'\n",
      " 'Silvio_Berlusconi' 'Andre_Agassi' 'Alvaro_Uribe' 'Halle_Berry'\n",
      " 'Tony_Blair' 'Gerhard_Schroeder' 'Andre_Agassi' 'George_W_Bush'\n",
      " 'Hu_Jintao' 'George_W_Bush' 'Alvaro_Uribe' 'Jacques_Chirac' 'Ian_Thorpe'\n",
      " 'Gerhard_Schroeder' 'John_Kerry' 'Silvio_Berlusconi' 'Lleyton_Hewitt'\n",
      " 'Alvaro_Uribe' 'Juan_Carlos_Ferrero' 'Amelie_Mauresmo' 'Jean_Chretien'\n",
      " 'Tommy_Franks' 'David_Beckham' 'Anna_Kournikova' 'Vicente_Fox'\n",
      " 'Andre_Agassi' 'George_W_Bush' 'Nicanor_Duarte_Frutos' 'Colin_Powell'\n",
      " 'Mahmoud_Abbas' 'Fidel_Castro' 'Tom_Daschle' 'Mohammed_Al-Douri'\n",
      " 'George_W_Bush' 'George_W_Bush' 'Tony_Blair' 'Jeremy_Greenstock'\n",
      " 'Hugo_Chavez' 'Nancy_Pelosi' 'Norah_Jones' 'Lindsay_Davenport'\n",
      " 'Gerhard_Schroeder' 'Serena_Williams' 'Hans_Blix' 'Kim_Ryong-sung'\n",
      " 'Halle_Berry' 'George_Robertson' 'David_Beckham' 'Kofi_Annan'\n",
      " 'Colin_Powell' 'Hamid_Karzai' 'George_W_Bush' 'Tom_Ridge' 'Sergey_Lavrov'\n",
      " 'Ariel_Sharon' 'Spencer_Abraham' 'Halle_Berry' 'Colin_Powell'\n",
      " 'George_W_Bush' 'Silvio_Berlusconi' 'Hugo_Chavez' 'Lindsay_Davenport'\n",
      " 'Gerhard_Schroeder' 'Tony_Blair' 'Lleyton_Hewitt' 'Hamid_Karzai'\n",
      " 'Donald_Rumsfeld' 'Tony_Blair' 'Andre_Agassi' 'Vicente_Fox' 'Hugo_Chavez'\n",
      " 'Charles_Moose' 'Jean_Chretien' 'Halle_Berry' 'Nestor_Kirchner'\n",
      " 'Walter_Mondale' 'Colin_Powell' 'Colin_Powell' 'George_W_Bush'\n",
      " 'Lleyton_Hewitt' 'Nancy_Pelosi' 'Nancy_Pelosi' 'Bill_McBride'\n",
      " 'Gerhard_Schroeder' 'Dick_Cheney' 'Tony_Blair' 'George_W_Bush'\n",
      " 'Nicanor_Duarte_Frutos' 'Colin_Powell' 'George_W_Bush' 'Condoleezza_Rice'\n",
      " 'Recep_Tayyip_Erdogan' 'Junichiro_Koizumi' 'George_W_Bush' 'Colin_Powell'\n",
      " 'Gerhard_Schroeder' 'George_W_Bush' 'Gerhard_Schroeder' 'Colin_Powell'\n",
      " 'Juan_Carlos_Ferrero' 'Colin_Powell' 'Gerhard_Schroeder' 'George_W_Bush'\n",
      " 'Donald_Rumsfeld' 'Carlos_Menem' 'Jennifer_Capriati' 'Rudolph_Giuliani'\n",
      " 'Yoriko_Kawaguchi' 'Alejandro_Toledo' 'Atal_Bihari_Vajpayee'\n",
      " 'Colin_Powell' 'Eduardo_Duhalde' 'Luiz_Inacio_Lula_da_Silva'\n",
      " 'Hugo_Chavez' 'Joe_Lieberman' 'Gerhard_Schroeder' 'Arnold_Schwarzenegger'\n",
      " 'Tony_Blair' 'Arnold_Schwarzenegger' 'Gerhard_Schroeder' 'Roh_Moo-hyun'\n",
      " 'John_Ashcroft' 'Jeremy_Greenstock' 'Gerhard_Schroeder' 'Tony_Blair'\n",
      " 'George_W_Bush' 'George_W_Bush' 'Serena_Williams' 'Jennifer_Lopez'\n",
      " 'John_Ashcroft' 'Dominique_de_Villepin' 'Serena_Williams' 'Nicole_Kidman'\n",
      " 'Rubens_Barrichello' 'Colin_Powell' 'George_W_Bush' 'George_W_Bush'\n",
      " 'Jacques_Chirac' 'Andre_Agassi' 'Jean_Chretien' 'Silvio_Berlusconi'\n",
      " 'Ricardo_Lagos' 'Guillermo_Coria' 'Paul_Bremer' 'Richard_Gephardt'\n",
      " 'Mohammed_Al-Douri' 'Pete_Sampras' 'Alejandro_Toledo'\n",
      " 'Juan_Carlos_Ferrero' 'Juan_Carlos_Ferrero' 'Jean_Chretien' 'Wen_Jiabao'\n",
      " 'Renee_Zellweger' 'Salma_Hayek' 'George_Robertson' 'George_W_Bush'\n",
      " 'Colin_Powell' 'Hugo_Chavez' 'Tony_Blair' 'George_W_Bush' 'Tony_Blair'\n",
      " 'George_W_Bush' 'Tony_Blair' 'Roh_Moo-hyun' 'Jack_Straw'\n",
      " 'Arnold_Schwarzenegger' 'Mahathir_Mohamad' 'Alejandro_Toledo'\n",
      " 'Colin_Powell' 'Bill_Clinton' 'Tony_Blair' 'Jennifer_Capriati'\n",
      " 'George_W_Bush' 'George_W_Bush' 'David_Nalbandian'\n",
      " 'Sergio_Vieira_De_Mello' 'Jack_Straw' 'Ariel_Sharon' 'Guillermo_Coria'\n",
      " 'Tim_Henman' 'Gerhard_Schroeder' 'Colin_Powell' 'George_W_Bush'\n",
      " 'Roger_Federer' 'Tony_Blair' 'Silvio_Berlusconi' 'Mahathir_Mohamad'\n",
      " 'Jason_Kidd' 'Ariel_Sharon' 'Donald_Rumsfeld' 'George_W_Bush'\n",
      " 'Jennifer_Capriati' 'Recep_Tayyip_Erdogan' 'Taha_Yassin_Ramadan'\n",
      " 'Nestor_Kirchner' 'Salma_Hayek' 'Colin_Powell' 'Ariel_Sharon'\n",
      " 'Silvio_Berlusconi' 'George_W_Bush' 'John_Snow' 'Serena_Williams'\n",
      " 'Alvaro_Uribe' 'Colin_Powell' 'George_W_Bush' 'Laura_Bush' 'Gray_Davis'\n",
      " 'Donald_Rumsfeld' 'Tommy_Thompson' 'Hugo_Chavez' 'Atal_Bihari_Vajpayee'\n",
      " 'George_W_Bush' 'Saddam_Hussein' 'Donald_Rumsfeld' 'Gerhard_Schroeder'\n",
      " 'Juan_Carlos_Ferrero' 'Tim_Henman' 'Tony_Blair' 'John_Ashcroft'\n",
      " 'Donald_Rumsfeld' 'Abdullah_Gul' 'George_Robertson' 'George_W_Bush'\n",
      " 'Colin_Powell' 'Adrien_Brody' 'Donald_Rumsfeld' 'Jacques_Chirac'\n",
      " 'Venus_Williams' 'Serena_Williams' 'Tony_Blair' 'Tony_Blair'\n",
      " 'Renee_Zellweger' 'George_W_Bush' 'Alejandro_Toledo' 'Condoleezza_Rice'\n",
      " 'Gerhard_Schroeder' 'Gerhard_Schroeder' 'Jacques_Chirac' 'Tony_Blair'\n",
      " 'Kim_Clijsters' 'Hamid_Karzai' 'Renee_Zellweger' 'George_W_Bush'\n",
      " 'Spencer_Abraham' 'Luiz_Inacio_Lula_da_Silva' 'Lance_Armstrong'\n",
      " 'Junichiro_Koizumi' 'George_W_Bush' 'Gerhard_Schroeder' 'Laura_Bush'\n",
      " 'George_W_Bush' 'Colin_Powell' 'Megawati_Sukarnoputri' 'Andre_Agassi'\n",
      " 'Hugo_Chavez' 'George_W_Bush' 'Alvaro_Uribe' 'Jean_Chretien'\n",
      " 'Colin_Powell' 'Colin_Powell' 'Nicole_Kidman' 'Colin_Powell'\n",
      " 'George_W_Bush' 'Kim_Clijsters' 'Tony_Blair' 'Jennifer_Capriati'\n",
      " 'Laura_Bush' 'George_W_Bush' 'Donald_Rumsfeld' 'Donald_Rumsfeld'\n",
      " 'George_W_Bush' 'Igor_Ivanov' 'Colin_Powell' 'Tony_Blair' 'George_W_Bush'\n",
      " 'Tiger_Woods' 'Donald_Rumsfeld' 'Sergio_Vieira_De_Mello' 'Ariel_Sharon'\n",
      " 'George_W_Bush' 'Jack_Straw' 'Recep_Tayyip_Erdogan' 'George_W_Bush'\n",
      " 'John_Allen_Muhammad' 'Ariel_Sharon' 'Tony_Blair' 'Alejandro_Toledo'\n",
      " 'Adrien_Brody' 'Tony_Blair' 'Tony_Blair' 'Gerhard_Schroeder'\n",
      " 'Nestor_Kirchner' 'Bill_Clinton' 'Taha_Yassin_Ramadan' 'Bill_McBride'\n",
      " 'George_W_Bush' 'George_W_Bush' 'Gloria_Macapagal_Arroyo'\n",
      " 'Queen_Elizabeth_II' 'Donald_Rumsfeld' 'Tom_Daschle' 'Tony_Blair'\n",
      " 'John_Bolton' 'Carlos_Menem' 'Nancy_Pelosi' 'Tim_Henman' 'Britney_Spears'\n",
      " 'Donald_Rumsfeld' 'Ariel_Sharon' 'Silvio_Berlusconi' 'David_Nalbandian'\n",
      " 'Megawati_Sukarnoputri' 'Colin_Powell' 'Keanu_Reeves' 'Laura_Bush'\n",
      " 'Recep_Tayyip_Erdogan' 'Joe_Lieberman' 'Alejandro_Toledo' 'Jiri_Novak'\n",
      " 'Gray_Davis' 'Jacques_Chirac' 'Abdullah_Gul' 'Guillermo_Coria'\n",
      " 'Junichiro_Koizumi' 'Condoleezza_Rice' 'Winona_Ryder' 'Bill_Clinton'\n",
      " 'Roger_Federer' 'Pete_Sampras' 'Renee_Zellweger' 'Meryl_Streep'\n",
      " 'Tony_Blair' 'Winona_Ryder' 'Gerhard_Schroeder' 'Ricardo_Lagos'\n",
      " 'Jacques_Rogge' 'Harrison_Ford' 'Gray_Davis' 'Jennifer_Lopez'\n",
      " 'Richard_Gere' 'George_W_Bush' 'George_W_Bush' 'Rubens_Barrichello'\n",
      " 'Kofi_Annan' 'Tony_Blair' 'John_Ashcroft' 'Bill_Gates' 'Tom_Hanks'\n",
      " 'Jennifer_Capriati' 'George_W_Bush' 'Bill_Simon' 'Serena_Williams'\n",
      " 'Pete_Sampras' 'Tony_Blair' 'Winona_Ryder' 'Julianne_Moore'\n",
      " 'Kim_Clijsters' 'George_Robertson' 'Nancy_Pelosi' 'Mahmoud_Abbas'\n",
      " 'George_W_Bush' 'Renee_Zellweger' 'George_W_Bush' 'Salma_Hayek'\n",
      " 'Rubens_Barrichello' 'John_Ashcroft' 'Jean_Chretien' 'Andy_Roddick'\n",
      " 'Laura_Bush' 'Kofi_Annan' 'Tony_Blair' 'Lleyton_Hewitt' 'Kofi_Annan'\n",
      " 'Recep_Tayyip_Erdogan' 'Andre_Agassi' 'Hugo_Chavez' 'Gerhard_Schroeder'\n",
      " 'Michael_Bloomberg' 'Gloria_Macapagal_Arroyo' 'Ariel_Sharon'\n",
      " 'Hugo_Chavez' 'Tiger_Woods' 'Roh_Moo-hyun' 'Tony_Blair' 'Laura_Bush'\n",
      " 'Howard_Dean' 'George_W_Bush' 'Tony_Blair' 'George_W_Bush' 'Bill_Gates'\n",
      " 'Tang_Jiaxuan' 'Tony_Blair' 'Richard_Gephardt' 'Roger_Federer'\n",
      " 'Andre_Agassi' 'Michael_Bloomberg' 'Mohammad_Khatami' 'Harrison_Ford'\n",
      " 'George_W_Bush' 'Renee_Zellweger' 'Donald_Rumsfeld' 'Vicente_Fox'\n",
      " 'Guillermo_Coria' 'George_W_Bush' 'Alejandro_Toledo' 'George_W_Bush'\n",
      " 'Arnold_Schwarzenegger' 'Richard_Gephardt' 'Abdullah_Gul' 'George_W_Bush'\n",
      " 'Jean_Chretien' 'James_Kelly' 'Taha_Yassin_Ramadan' 'Tony_Blair'\n",
      " 'Jean_Chretien' 'Recep_Tayyip_Erdogan' 'Hugo_Chavez' 'Colin_Powell'\n",
      " 'Colin_Powell' 'David_Nalbandian' 'Sergey_Lavrov' 'Recep_Tayyip_Erdogan'\n",
      " 'Wen_Jiabao' 'Vladimir_Putin' 'George_Robertson' 'Ian_Thorpe'\n",
      " 'Joschka_Fischer' 'George_W_Bush' 'Gerhard_Schroeder' 'Jeremy_Greenstock'\n",
      " 'Michael_Schumacher' 'Serena_Williams' 'Colin_Powell' 'Donald_Rumsfeld'\n",
      " 'George_W_Bush' 'Kofi_Annan' 'James_Kelly' 'Lindsay_Davenport'\n",
      " 'Carlos_Moya' 'Andre_Agassi' 'Wen_Jiabao' 'George_W_Bush' 'Abdullah_Gul'\n",
      " 'David_Beckham' 'Juan_Carlos_Ferrero' 'George_W_Bush' 'Tiger_Woods'\n",
      " 'Hamid_Karzai' 'Gerhard_Schroeder' 'Joschka_Fischer' 'Tony_Blair'\n",
      " 'Hugo_Chavez' 'Tony_Blair' 'Charles_Moose' 'Jennifer_Lopez'\n",
      " 'George_W_Bush' 'John_Paul_II' 'George_W_Bush' 'George_W_Bush'\n",
      " 'Nicole_Kidman' 'Tang_Jiaxuan' 'Fidel_Castro' 'George_W_Bush'\n",
      " 'George_W_Bush' 'Donald_Rumsfeld' 'Renee_Zellweger' 'Tony_Blair'\n",
      " 'Andre_Agassi' 'Bill_McBride' 'Paradorn_Srichaphan' 'Hugo_Chavez'\n",
      " 'Nicole_Kidman' 'Abdullah_Gul' 'Meryl_Streep' 'Muhammad_Ali'\n",
      " 'Kim_Ryong-sung' 'Tony_Blair' 'Julie_Gerberding' 'David_Beckham'\n",
      " 'Arnold_Schwarzenegger' 'John_Ashcroft' 'Pete_Sampras' 'Colin_Powell'\n",
      " 'Dick_Cheney' 'Lance_Armstrong' 'Tony_Blair' 'Andy_Roddick'\n",
      " 'Ariel_Sharon' 'Gerhard_Schroeder' 'Gerhard_Schroeder' 'George_W_Bush'\n",
      " 'Tom_Ridge' 'Colin_Powell' 'George_W_Bush' 'Nestor_Kirchner'\n",
      " 'Carlos_Moya' 'George_W_Bush' 'Donald_Rumsfeld' 'Donald_Rumsfeld'\n",
      " 'Rubens_Barrichello' 'Mohammed_Al-Douri' 'Gerhard_Schroeder'\n",
      " 'Serena_Williams' 'Gerhard_Schroeder' 'Lindsay_Davenport'\n",
      " 'Vladimir_Putin' 'Tony_Blair' 'Naomi_Watts' 'George_W_Bush'\n",
      " 'Colin_Powell' 'Harrison_Ford' 'John_Kerry' 'Junichiro_Koizumi'\n",
      " 'Trent_Lott' 'Tom_Ridge' 'Laura_Bush' 'Dominique_de_Villepin'\n",
      " 'Serena_Williams' 'Alvaro_Uribe' 'Lleyton_Hewitt' 'Lleyton_Hewitt'\n",
      " 'Vladimir_Putin' 'Donald_Rumsfeld' 'Richard_Gephardt' 'John_Snow'\n",
      " 'George_W_Bush' 'Kim_Ryong-sung' 'Harrison_Ford' 'Gerhard_Schroeder'\n",
      " 'Jean_Chretien' 'Donald_Rumsfeld' 'Donald_Rumsfeld' 'Joschka_Fischer'\n",
      " 'Jose_Maria_Aznar' 'Fidel_Castro' 'Colin_Powell' 'Tony_Blair'\n",
      " 'Jason_Kidd' 'Jiri_Novak' 'Megawati_Sukarnoputri' 'Jose_Maria_Aznar'\n",
      " 'Halle_Berry' 'Jacques_Chirac' 'Donald_Rumsfeld' 'Britney_Spears'\n",
      " 'Gerhard_Schroeder' 'Colin_Powell' 'Donald_Rumsfeld' 'Ian_Thorpe'\n",
      " 'Amelie_Mauresmo' 'Donald_Rumsfeld' 'George_W_Bush' 'George_Robertson'\n",
      " 'Dominique_de_Villepin' 'Saddam_Hussein' 'Hugo_Chavez' 'George_W_Bush'\n",
      " 'Jackie_Chan' 'Donald_Rumsfeld' 'Jose_Maria_Aznar'\n",
      " 'Arnold_Schwarzenegger' 'Pierce_Brosnan' 'Jack_Straw' 'John_Howard'\n",
      " 'Jennifer_Capriati' 'Bill_Clinton' 'Jean_Chretien' 'Tony_Blair'\n",
      " 'George_W_Bush' 'Nicole_Kidman' 'Recep_Tayyip_Erdogan' 'Colin_Powell'\n",
      " 'Rudolph_Giuliani' 'Andre_Agassi' 'George_W_Bush' 'Jacques_Chirac'\n",
      " 'Jennifer_Lopez' 'Alvaro_Uribe']\n"
     ]
    }
   ],
   "source": [
    "y_pred_names_10 = []\n",
    "\n",
    "for label in y_pred_10:\n",
    "    y_pred_names_10.append(y_train_labels_to_names[label])\n",
    "    \n",
    "y_pred_names_10 = np.array(y_pred_names_10)\n",
    "print(y_pred_names_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_names is:  Renee_Zellweger  and  y_test name is:  Renee_Zellweger\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Gerhard_Schroeder  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Julie_Gerberding  and  y_test name is:  Julie_Gerberding\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  John_Allen_Muhammad  and  y_test name is:  John_Allen_Muhammad\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  Ariel_Sharon  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  Pierce_Brosnan  and  y_test name is:  Pierce_Brosnan\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Tony_Blair  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Tony_Blair  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Junichiro_Koizumi  and  y_test name is:  Junichiro_Koizumi\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Ariel_Sharon  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Guillermo_Coria  and  y_test name is:  Guillermo_Coria\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  Andre_Agassi  and  y_test name is:  Andre_Agassi\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Recep_Tayyip_Erdogan  and  y_test name is:  Recep_Tayyip_Erdogan\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Jennifer_Capriati  and  y_test name is:  Jennifer_Capriati\n",
      "y_pred_names is:  Tony_Blair  and  y_test name is:  Tony_Blair\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Juan_Carlos_Ferrero  and  y_test name is:  Juan_Carlos_Ferrero\n",
      "y_pred_names is:  Salma_Hayek  and  y_test name is:  Salma_Hayek\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  Hugo_Chavez  and  y_test name is:  Hugo_Chavez\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Guillermo_Coria  and  y_test name is:  Guillermo_Coria\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Silvio_Berlusconi  and  y_test name is:  Silvio_Berlusconi\n",
      "y_pred_names is:  Ariel_Sharon  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Donald_Rumsfeld  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Juan_Carlos_Ferrero  and  y_test name is:  Juan_Carlos_Ferrero\n",
      "y_pred_names is:  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Hamid_Karzai  and  y_test name is:  Hamid_Karzai\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Megawati_Sukarnoputri  and  y_test name is:  Megawati_Sukarnoputri\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Gloria_Macapagal_Arroyo  and  y_test name is:  Gloria_Macapagal_Arroyo\n",
      "y_pred_names is:  Britney_Spears  and  y_test name is:  Britney_Spears\n",
      "y_pred_names is:  David_Nalbandian  and  y_test name is:  David_Nalbandian\n",
      "y_pred_names is:  Colin_Powell  and  y_test name is:  Colin_Powell\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Bill_Gates  and  y_test name is:  Bill_Gates\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Julianne_Moore  and  y_test name is:  Julianne_Moore\n",
      "y_pred_names is:  Renee_Zellweger  and  y_test name is:  Renee_Zellweger\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Recep_Tayyip_Erdogan  and  y_test name is:  Recep_Tayyip_Erdogan\n",
      "y_pred_names is:  Ariel_Sharon  and  y_test name is:  Ariel_Sharon\n",
      "y_pred_names is:  Tiger_Woods  and  y_test name is:  Tiger_Woods\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Donald_Rumsfeld  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Andre_Agassi  and  y_test name is:  Andre_Agassi\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Serena_Williams  and  y_test name is:  Serena_Williams\n",
      "y_pred_names is:  John_Kerry  and  y_test name is:  John_Kerry\n",
      "y_pred_names is:  Laura_Bush  and  y_test name is:  Laura_Bush\n",
      "y_pred_names is:  Lleyton_Hewitt  and  y_test name is:  Lleyton_Hewitt\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Jean_Chretien  and  y_test name is:  Jean_Chretien\n",
      "y_pred_names is:  Jiri_Novak  and  y_test name is:  Jiri_Novak\n",
      "y_pred_names is:  Megawati_Sukarnoputri  and  y_test name is:  Megawati_Sukarnoputri\n",
      "y_pred_names is:  Donald_Rumsfeld  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  Gerhard_Schroeder  and  y_test name is:  Gerhard_Schroeder\n",
      "y_pred_names is:  Donald_Rumsfeld  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "y_pred_names is:  Donald_Rumsfeld  and  y_test name is:  Donald_Rumsfeld\n",
      "y_pred_names is:  George_W_Bush  and  y_test name is:  George_W_Bush\n",
      "\n",
      "\n",
      "Accuracy is this:  0.14450867052023122\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(y_pred_names_10)):\n",
    "    if y_pred_names_10[i] == y_test[i]:\n",
    "        print(\"y_pred_names is: \",y_pred_names_10[i] ,\" and \",\"y_test name is: \",y_test[i])\n",
    "        count+=1\n",
    "        \n",
    "accuracy = count/len(y_pred_names_10)\n",
    "    \n",
    "print(\"\\n\\nAccuracy is this: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seperately Training The HoG,CNN and lbp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3459, 944) (865, 944) (3459, 2048) (865, 2048) (3459, 255) (865, 255)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_train_hog = X_train[:,1:945]\n",
    "X_test_hog = X_test[:,1:945]\n",
    "\n",
    "X_train_cnn = X_train[:,945:2993]\n",
    "X_test_cnn = X_test[:,945:2993]\n",
    "\n",
    "X_train_lbp = X_train[:,2993:]\n",
    "X_test_lbp = X_test[:,2993:]\n",
    "\n",
    "print(X_train_hog.shape,X_test_hog.shape,X_train_cnn.shape,X_test_cnn.shape,X_train_lbp.shape,X_test_lbp.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train On HoG Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3459,)\n",
      "float64 int64\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swaksh/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.1308 - loss: 4.6380\n",
      "Epoch 2/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.2615 - loss: 3.6041\n",
      "Epoch 3/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4784 - loss: 2.2389\n",
      "Epoch 4/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7717 - loss: 0.9340\n",
      "Epoch 5/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9411 - loss: 0.2501\n",
      "Epoch 6/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9912 - loss: 0.0516\n",
      "Epoch 7/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0099\n",
      "Epoch 8/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0062\n",
      "Epoch 9/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0082\n",
      "Epoch 10/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 11/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.7334e-04\n",
      "Epoch 12/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.1890e-04\n",
      "Epoch 13/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.4046e-04\n",
      "Epoch 14/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.6927e-04\n",
      "Epoch 15/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.1703e-04\n",
      "Epoch 16/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.8355e-04\n",
      "Epoch 17/250\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.5152e-04\n",
      "Epoch 18/250\n",
      "\u001b[1m 1/55\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.8369e-04"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers,models\n",
    "import torch\n",
    "\n",
    "model_hog = keras.Sequential([\n",
    "    keras.layers.Dense(2048,activation='relu',input_shape=(944,)),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(158,activation='softmax'),  # Here 4883 are my unique labels\n",
    "    \n",
    "])\n",
    "\n",
    "model_hog.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train_hog = np.array(X_train_hog)\n",
    "y_train = np.array(y_train)\n",
    "print(X_train_hog.dtype,y_train.dtype)\n",
    "model_hog.fit(X_train_hog,y_train,epochs=250,batch_size=64)\n",
    "\n",
    "\n",
    "X_test_hog = np.array(X_test_hog)\n",
    "y_test = np.array(y_test)\n",
    "predictions_10_hog = model_hog.predict(X_test_hog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From The Mapped lables To Names Get y_pred_hog Names And Accuracy Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hog = []\n",
    "for pred in predictions_10_hog:\n",
    "    y_pred_hog.append(np.argmax(pred))\n",
    "    \n",
    "y_pred_hog = np.array(y_pred_hog)\n",
    "print(y_pred_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hog_names = []\n",
    "\n",
    "for label in y_pred_hog:\n",
    "    y_pred_hog_names.append(y_train_labels_to_names[label])\n",
    "    \n",
    "y_pred_hog_names = np.array(y_pred_hog_names)\n",
    "print(y_pred_hog_names)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_pred_hog_names)):\n",
    "    if y_pred_hog_names[i] == y_test[i]:\n",
    "        print(\"y_pred_names of hog is: \",y_pred_hog_names[i] ,\" and \",\"y_test name is: \",y_test[i])\n",
    "        count+=1\n",
    "        \n",
    "accuracy_hog = count/len(y_pred_hog_names)\n",
    "    \n",
    "print(\"\\n\\nAccuracy is this: \",accuracy_hog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train On CNN Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers,models\n",
    "import torch\n",
    "\n",
    "model_cnn = keras.Sequential([\n",
    "    keras.layers.Dense(2048,activation='relu',input_shape=(2048,)),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(158,activation='softmax'),  # Here 4883 are my unique labels\n",
    "    \n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train_cnn = np.array(X_train_cnn)\n",
    "y_train = np.array(y_train)\n",
    "model_cnn.fit(X_train_cnn,y_train,epochs=250,batch_size=64)\n",
    "\n",
    "X_test_cnn = np.array(X_test_cnn)\n",
    "y_test = np.array(y_test)\n",
    "predictions_10_cnn = model_cnn.predict(X_test_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From The Mapped lables To Names Get y_pred_cnn Names And Accuracy Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn = []\n",
    "for prediction in predictions_10_cnn:\n",
    "    y_pred_cnn.append(np.argmax(prediction))\n",
    "    \n",
    "y_pred_cnn = np.array(y_pred_cnn)\n",
    "print(y_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn_names = []\n",
    "\n",
    "for label in y_pred_cnn:\n",
    "    y_pred_cnn_names.append(y_train_labels_to_names[label])\n",
    "    \n",
    "y_pred_cnn_names = np.array(y_pred_cnn_names)\n",
    "print(y_pred_cnn_names)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_pred_cnn_names)):\n",
    "    if y_pred_cnn_names[i] == y_test[i]:\n",
    "        print(\"y_pred_names of cnn is: \",y_pred_cnn_names[i] ,\" and \",\"y_test name is: \",y_test[i])\n",
    "        count+=1\n",
    "        \n",
    "accuracy_cnn = count/len(y_pred_cnn_names)\n",
    "    \n",
    "print(\"\\n\\nAccuracy is this: \",accuracy_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model On lbp Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers,models\n",
    "import torch\n",
    "\n",
    "model_lbp = keras.Sequential([\n",
    "    keras.layers.Dense(2048,activation='relu',input_shape=(255,)),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(158,activation='softmax'),  # Here 4883 are my unique labels\n",
    "    \n",
    "])\n",
    "\n",
    "model_lbp.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train_lbp = np.array(X_train_lbp)\n",
    "y_train = np.array(y_train)\n",
    "model_lbp.fit(X_train_lbp,y_train,epochs=250,batch_size=64)\n",
    "\n",
    "X_test_lbp = np.array(X_test_lbp)\n",
    "y_test = np.array(y_test)\n",
    "predictions_10_lbp = model_lbp.predict(X_test_lbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From The Mapped lables To Names Get y_pred_lbp Names And Accuracy Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lbp = []\n",
    "for prediction in predictions_10_lbp:\n",
    "    y_pred_lbp.append(np.argmax(prediction))\n",
    "    \n",
    "y_pred_lbp = np.array(y_pred_lbp)\n",
    "print(y_pred_lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lbp_names = []\n",
    "\n",
    "for label in y_pred_lbp:\n",
    "    y_pred_lbp_names.append(y_train_labels_to_names[label])\n",
    "    \n",
    "y_pred_lbp_names = np.array(y_pred_lbp_names)\n",
    "print(y_pred_lbp_names)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_pred_lbp_names)):\n",
    "    if y_pred_lbp_names[i] == y_test[i]:\n",
    "        print(\"y_pred_names of lbp is: \",y_pred_lbp_names[i] ,\" and \",\"y_test name is: \",y_test[i])\n",
    "        count+=1\n",
    "        \n",
    "accuracy_lbp = count/len(y_pred_lbp_names)\n",
    "    \n",
    "print(\"\\n\\nAccuracy is this: \",accuracy_lbp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
